{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **SMILES 文字列生成のための変分オートエンコーダ（VAE）**\n",
        "本プロジェクトでは、**SMILES（Simplified Molecular Input Line Entry System）** という化学構造式の表記法を対象に、**変分オートエンコーダ（VAE）** を用いて学習・生成するモデルを構築しました。以下に、全体の処理の流れをまとめます。\n",
        "\n",
        "---\n",
        "\n",
        "## **1. ライブラリのインポートと環境設定**\n",
        "```python\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from rdkit import Chem, RDLogger\n",
        "from google.colab import drive\n",
        "```\n",
        "- **Google Drive をマウント** し、学習データを取得。\n",
        "- **RDKit（化学分子処理ライブラリ）** を使用し、ログを無効化。\n",
        "\n",
        "---\n",
        "\n",
        "## **2. データの準備**\n",
        "```python\n",
        "directory = '/content/drive/My Drive/day6'\n",
        "property_df = pd.read_csv(os.path.join(directory, 'property_df.csv'))\n",
        "```\n",
        "- Google Drive 内の CSV ファイルから **SMILES データを読み込み**。\n",
        "\n",
        "```python\n",
        "vocab_freq = {}\n",
        "word_length_dist = []\n",
        "for smile in property_df[\"Open Babel SMILES\"]:\n",
        "    for s in smile:\n",
        "        vocab_freq[s] = vocab_freq.get(s, 0) + 1\n",
        "    word_length_dist.append(len(smile))\n",
        "\n",
        "vocab = list(vocab_freq.keys())\n",
        "N_INPUT = len(vocab) * 128\n",
        "```\n",
        "- **SMILES 文字列のトークンを解析し、語彙（vocab）を作成**。\n",
        "- **最大文字長を 128 に統一**。\n",
        "\n",
        "---\n",
        "\n",
        "## **3. SMILES 文字列を数値ベクトル化**\n",
        "```python\n",
        "def smile2vec(vocab, vecsize, smile):\n",
        "    vec = []\n",
        "    for i in range(vecsize):\n",
        "        v = [0 for _ in range(len(vocab))]\n",
        "        if i < len(smile):\n",
        "            v[vocab.index(smile[i])] = 1\n",
        "        vec += v\n",
        "    return vec\n",
        "```\n",
        "- SMILES の各文字を **One-hot ベクトルに変換** し、固定長 `vecsize=128` にする。\n",
        "\n",
        "```python\n",
        "X = np.array([smile2vec(vocab, 128, smile) for smile in property_df[\"Open Babel SMILES\"]])\n",
        "X_tensor = torch.from_numpy(X).float()\n",
        "dataset = TensorDataset(X_tensor)\n",
        "data_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "```\n",
        "- **データセットを PyTorch 用に変換し、DataLoader に格納**。\n",
        "\n",
        "---\n",
        "\n",
        "## **4. 変分オートエンコーダ（VAE）の実装**\n",
        "```python\n",
        "class VAE(torch.nn.Module):\n",
        "    def __init__(self, n_input=784, n_hidden=400, n_z=20):\n",
        "        super(VAE, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(n_input, n_hidden)\n",
        "        self.fc2 = torch.nn.Linear(n_hidden, n_z)  # μ\n",
        "        self.fc3 = torch.nn.Linear(n_hidden, n_z)  # log(σ^2)\n",
        "        self.fc4 = torch.nn.Linear(n_z, n_hidden)\n",
        "        self.fc5 = torch.nn.Linear(n_hidden, n_input)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = torch.nn.functional.relu(self.fc1(x))\n",
        "        return self.fc2(h), self.fc3(h)  # μ, log(σ^2)\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(log_var / 2)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std  # 再パラメータ化\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = torch.nn.functional.relu(self.fc4(z))\n",
        "        return torch.sigmoid(self.fc5(h))  # 生成データ\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encode(x)\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        return self.decode(z), mu, log_var\n",
        "```\n",
        "- **エンコーダ**: `x → h → (μ, log(σ^2))`\n",
        "- **再パラメータ化**: `z = μ + εσ`\n",
        "- **デコーダ**: `z → h → x'`\n",
        "- **出力**: `x'`（再構成された SMILES）\n",
        "\n",
        "---\n",
        "\n",
        "## **5. 損失関数と学習**\n",
        "```python\n",
        "model = VAE(n_input=N_INPUT, n_hidden=400, n_z=20).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "```\n",
        "- **Adam オプティマイザで学習**。\n",
        "\n",
        "```python\n",
        "for epoch in range(20):\n",
        "    for i, x in enumerate(data_loader):\n",
        "        x = x[0].to(device).view(-1, N_INPUT)\n",
        "        x_reconst, mu, log_var = model(x)\n",
        "\n",
        "        reconst_loss = torch.nn.functional.binary_cross_entropy(x_reconst, x, reduction='sum')\n",
        "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "        loss = reconst_loss + kl_div\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "```\n",
        "- **再構成誤差（Binary Cross Entropy）** + **KL ダイバージェンス** を最小化。\n",
        "\n",
        "```python\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(16, 20).to(device)\n",
        "        out = model.decode(z)\n",
        "        print(\"Epoch[{}/{}], Generated SMILES: {}\".format(epoch+1, 20, get_best_smile(out)))\n",
        "```\n",
        "- **学習後に新しい SMILES を生成**。\n",
        "\n",
        "---\n",
        "\n",
        "## **6. SMILES の復元関数**\n",
        "```python\n",
        "def get_best_smile(out_tensor):\n",
        "    best_smile = \"\"\n",
        "    for vec in out_tensor:\n",
        "        vec = vec.reshape(128, len(vocab))\n",
        "        smile = \"\".join([vocab[torch.argmax(v).item()] for v in vec])\n",
        "        mol = Chem.MolFromSmiles(smile)\n",
        "\n",
        "        while not mol:\n",
        "            if len(smile) == 0: break\n",
        "            smile = smile[:-1]\n",
        "            mol = Chem.MolFromSmiles(smile)\n",
        "\n",
        "        if len(best_smile) < len(smile):\n",
        "            best_smile = smile\n",
        "    return best_smile\n",
        "```\n",
        "- **One-hot ベクトル → SMILES 文字列に変換**。\n",
        "- **無効な SMILES は修正**（末尾から1文字ずつ削除）。\n",
        "\n",
        "---\n",
        "\n",
        "# **まとめ**\n",
        "本プロジェクトでは、**変分オートエンコーダ（VAE）を用いた SMILES 文字列の生成** を行いました。\n",
        "\n",
        "### **実装のポイント**\n",
        "1. **SMILES データの前処理**\n",
        "   - One-hot エンコーディングで固定長ベクトル化。\n",
        "2. **VAE モデルの設計**\n",
        "   - エンコーダで `μ, log(σ^2)` を求め、再パラメータ化。\n",
        "   - デコーダで `z` から SMILES を再構成。\n",
        "3. **損失関数**\n",
        "   - `BCE`（再構成誤差）+ `KL ダイバージェンス`。\n",
        "4. **学習**\n",
        "   - PyTorch の `Adam` オプティマイザを使用。\n",
        "5. **生成**\n",
        "   - 学習後、`z ~ N(0,1)` から新しい SMILES を生成。\n",
        "\n",
        "### **期待される応用**\n",
        "- **新規化合物の探索**\n",
        "- **分子生成モデルの構築**\n",
        "- **化学構造のデータ拡張**\n",
        "\n",
        "VAE による分子生成は **新しい医薬品や材料の設計** にも応用可能であり、今後の発展が期待される技術です！"
      ],
      "metadata": {
        "id": "S6KEdnwS7qzb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaxNnuoC_PzO",
        "outputId": "e8dd8e09-3713-47c7-dd8e-6035bf642f5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、PyTorch を用いて計算を行うデバイス（CPU または GPU）を自動的に選択する処理を行っています。以下に詳しく解説します。\n",
        "\n",
        "---\n",
        "\n",
        "### **コードの解説**\n",
        "```python\n",
        "import torch\n",
        "```\n",
        "- PyTorch のライブラリをインポートします。\n",
        "\n",
        "```python\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "```\n",
        "- `torch.cuda.is_available()` は、CUDA に対応した GPU が使用可能かどうかを判定する関数です。\n",
        "  - GPU が使用可能な場合 (`True`)、`'cuda'` を返します。\n",
        "  - GPU が使用できない場合 (`False`)、`'cpu'` を返します。\n",
        "- `torch.device()` は、テンソルやモデルをどのデバイス（CPU または GPU）に配置するかを指定するためのオブジェクトを作成します。\n",
        "- 結果として、GPU が利用可能であれば `device` には `'cuda'` が設定され、GPU が使えない場合は `'cpu'` が設定されます。\n",
        "\n",
        "```python\n",
        "device\n",
        "```\n",
        "- `device` を出力すると、現在選択されているデバイス（`'cuda'` または `'cpu'`）が表示されます。\n",
        "\n",
        "---\n",
        "\n",
        "### **このコードの用途**\n",
        "- PyTorch を用いた機械学習・深層学習のプログラムでは、計算を GPU で行うことで高速化できます。\n",
        "- このコードを使うことで、GPU が使える環境では自動的に GPU を使用し、そうでない場合は CPU を使用するようにできます。\n",
        "\n",
        "---\n",
        "\n",
        "### **実際の使用例**\n",
        "例えば、モデルやテンソルを `device` に適用することで、適切なデバイス上で計算を行えます。\n",
        "\n",
        "```python\n",
        "# デバイスの選択\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# デバイス情報の表示\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Tensorをデバイスに移動\n",
        "x = torch.tensor([1.0, 2.0, 3.0]).to(device)\n",
        "print(x.device)  # 選択されたデバイスが表示される\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **まとめ**\n",
        "- `torch.device('cuda' if torch.cuda.is_available() else 'cpu')` は、利用可能な計算デバイス（GPU か CPU）を自動的に選択する。\n",
        "- GPU が使える場合は `cuda`、使えない場合は `cpu` が選択される。\n",
        "- `device` を指定してテンソルやモデルを適切なデバイスに移動させることで、計算を最適化できる。\n",
        "\n",
        "このコードは、PyTorch を使う際の基本的なベストプラクティスの一つなので、覚えておくと便利です！"
      ],
      "metadata": {
        "id": "bWQ3epKkyQHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "directory = '/content/drive/My Drive/day6'\n",
        "property_df = pd.read_csv(os.path.join(directory, 'property_df.csv'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAtkN0VL_TuI",
        "outputId": "c68673f5-7f57-4c0b-ea4f-ee59f4ca61fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、Google Colab で Google ドライブをマウントし、指定したディレクトリ内の CSV ファイルを `pandas` のデータフレームとして読み込む処理を行っています。以下、詳しく解説します。\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの解説**\n",
        "\n",
        "### **1. Google ドライブのマウント**\n",
        "```python\n",
        "from google.colab import drive\n",
        "```\n",
        "- Google Colab で Google ドライブを操作するための `drive` モジュールをインポートします。\n",
        "\n",
        "```python\n",
        "drive.mount('/content/drive')\n",
        "```\n",
        "- Google ドライブを `/content/drive` にマウントします。\n",
        "- 実行すると、認証を求められるので、表示されるリンクを開き、Google アカウントでログインして認証コードをコピーして貼り付ける必要があります。\n",
        "- マウント後、Google ドライブのファイルにローカルのようにアクセスできるようになります。\n",
        "\n",
        "---\n",
        "\n",
        "### **2. `pandas` と `os` のインポート**\n",
        "```python\n",
        "import pandas as pd\n",
        "import os\n",
        "```\n",
        "- `pandas` はデータ分析のためのライブラリで、CSV ファイルの読み込みなどに使用します。\n",
        "- `os` はファイルパスの結合 (`os.path.join`) など、OS に依存した操作をするための標準ライブラリです。\n",
        "\n",
        "---\n",
        "\n",
        "### **3. データの読み込み**\n",
        "```python\n",
        "directory = '/content/drive/My Drive/day6'\n",
        "```\n",
        "- Google ドライブ内の `\"My Drive/day6\"` フォルダのパスを指定します。\n",
        "- `My Drive` は Google ドライブのルートディレクトリに相当します。\n",
        "\n",
        "```python\n",
        "property_df = pd.read_csv(os.path.join(directory, 'property_df.csv'))\n",
        "```\n",
        "- `os.path.join(directory, 'property_df.csv')` によって `\"My Drive/day6/property_df.csv\"` というフルパスを作成します。\n",
        "- `pd.read_csv()` を使い、指定した CSV ファイルをデータフレーム (`property_df`) として読み込みます。\n",
        "\n",
        "---\n",
        "\n",
        "## **補足**\n",
        "1. **Google ドライブ内のファイルを使う理由**\n",
        "   - Colab は仮想環境のため、ランタイムをリセットするとローカルファイルが消えます。\n",
        "   - Google ドライブにデータを保存しておくと、再実行時にファイルを再利用できます。\n",
        "\n",
        "2. **Google ドライブ内のファイルパスの確認**\n",
        "   - Google ドライブをマウントした後、次のコマンドでドライブ内のフォルダやファイルを確認できます。\n",
        "     ```python\n",
        "     !ls /content/drive/My\\ Drive/day6\n",
        "     ```\n",
        "   - もし `FileNotFoundError` が発生したら、指定した `directory` にファイルが存在するかを確認してください。\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "- Google ドライブをマウントして Colab でファイルを扱えるようにする。\n",
        "- `pd.read_csv()` を使い、Google ドライブ内の CSV ファイルを `pandas` のデータフレームとして読み込む。\n",
        "- `os.path.join()` を使うことで OS に依存しないパスを作成できる。\n",
        "\n",
        "この方法を使えば、大量のデータを Colab で効率的に扱うことができます！"
      ],
      "metadata": {
        "id": "tx0u-fSjyhU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SMILES_COL = \"Open Babel SMILES\"\n",
        "SMILES_MAXLEN = 128\n",
        "BATCH_SIZE = 16\n",
        "N_HIDDEN = 400\n",
        "N_Z = 20\n",
        "LEARNING_RATE = 1e-3\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "vocab_freq =  {}\n",
        "word_length_dist = []\n",
        "for smile in property_df[SMILES_COL]:\n",
        "    for s in smile:\n",
        "        if s not in vocab_freq.keys():\n",
        "            vocab_freq[s] = 0\n",
        "        vocab_freq[s] += 1\n",
        "    word_length_dist.append(len(smile))\n",
        "\n",
        "vocab = list(vocab_freq.keys())\n",
        "N_INPUT = len(vocab)*SMILES_MAXLEN"
      ],
      "metadata": {
        "id": "0Ov0WLQb_chZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、**SMILES（Simplified Molecular Input Line Entry System）表記の分子データを処理し、文字の頻度分布を作成する前処理**を行っています。主に、SMILES データの特徴を抽出し、ニューラルネットワークの入力サイズを計算するために使用されます。\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの解説**\n",
        "\n",
        "### **1. ハイパーパラメータの定義**\n",
        "```python\n",
        "SMILES_COL = \"Open Babel SMILES\"\n",
        "SMILES_MAXLEN = 128\n",
        "BATCH_SIZE = 16\n",
        "N_HIDDEN = 400\n",
        "N_Z = 20\n",
        "LEARNING_RATE = 1e-3\n",
        "NUM_EPOCHS = 20\n",
        "```\n",
        "- **`SMILES_COL`**: SMILES データが格納されている `property_df` のカラム名を指定。\n",
        "- **`SMILES_MAXLEN`**: SMILES 文字列の最大長。短いものはパディングされる可能性がある。\n",
        "- **`BATCH_SIZE`**: 学習時のバッチサイズ（1 回の更新で処理するデータ数）。\n",
        "- **`N_HIDDEN`**: 隠れ層のニューロン数（ニューラルネットワークの層のサイズ）。\n",
        "- **`N_Z`**: 潜在変数（潜在空間の次元数、VAE などの生成モデルで使う）。\n",
        "- **`LEARNING_RATE`**: 学習率（勾配降下法の更新幅）。\n",
        "- **`NUM_EPOCHS`**: エポック数（データセット全体を何回学習するか）。\n",
        "\n",
        "---\n",
        "\n",
        "### **2. SMILES データの頻度分析**\n",
        "```python\n",
        "vocab_freq = {}\n",
        "word_length_dist = []\n",
        "```\n",
        "- **`vocab_freq`**: SMILES 文字（原子記号や結合情報など）の出現回数を記録する辞書。\n",
        "- **`word_length_dist`**: 各 SMILES 文字列の長さを保存するリスト。\n",
        "\n",
        "```python\n",
        "for smile in property_df[SMILES_COL]:  # 各 SMILES 文字列に対して\n",
        "    for s in smile:  # 文字ごとにループ\n",
        "        if s not in vocab_freq.keys():  # 初めて出現する文字なら辞書に追加\n",
        "            vocab_freq[s] = 0\n",
        "        vocab_freq[s] += 1  # 出現回数をカウント\n",
        "    word_length_dist.append(len(smile))  # 文字列の長さを保存\n",
        "```\n",
        "- **`vocab_freq` の役割**\n",
        "  - すべての SMILES 文字列をスキャンし、各文字（原子記号、結合記号など）が何回登場するかをカウントする。\n",
        "  - 例: `vocab_freq = {'C': 500, 'O': 200, '=': 100, ...}`\n",
        "\n",
        "- **`word_length_dist` の役割**\n",
        "  - 各 SMILES の長さを記録し、長さの統計を取るために使用。\n",
        "  - 例: `word_length_dist = [25, 30, 22, 28, ...]`\n",
        "\n",
        "---\n",
        "\n",
        "### **3. 語彙リストと入力次元の計算**\n",
        "```python\n",
        "vocab = list(vocab_freq.keys())  # ユニークな SMILES 文字のリスト\n",
        "N_INPUT = len(vocab) * SMILES_MAXLEN  # 入力次元数\n",
        "```\n",
        "- **`vocab`**: 見つかったユニークな文字をリスト化（辞書のキーを取得）。\n",
        "  - 例: `vocab = ['C', 'O', 'N', '=', '#', '(', ')', ...]`\n",
        "  - このリストの長さが、1-hot エンコーディングで使う語彙サイズになる。\n",
        "\n",
        "- **`N_INPUT`**: ニューラルネットワークの入力次元を計算。\n",
        "  - 文字の種類 `len(vocab)` × 文字列の最大長 `SMILES_MAXLEN`\n",
        "  - 例: `N_INPUT = 50 * 128 = 6400`\n",
        "  - SMILES を 1-hot ベクトルでエンコードする場合、この値がニューラルネットの入力サイズになる。\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの目的**\n",
        "このコードの主な目的は、**SMILES 文字列の前処理と、ニューラルネットワークの入力サイズの決定**です。\n",
        "- **文字ごとの頻度を計算** → SMILES を効率的に処理できるようにする。\n",
        "- **語彙リストを作成** → ニューラルネットの入力を定義。\n",
        "- **入力次元を計算** → モデルの構造を設計する際に必要。\n",
        "\n",
        "---\n",
        "\n",
        "## **応用例**\n",
        "このデータは、**ニューラルネットワーク（VAE や RNN など）を使った分子生成・予測タスク** に利用できます。\n",
        "- **VAE（Variational Autoencoder）**: SMILES を潜在空間にマッピングして、新しい分子を生成。\n",
        "- **RNN（Recurrent Neural Network）**: SMILES 文字列を時系列データとして処理し、分子の特性を予測。\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "1. **ハイパーパラメータの設定**\n",
        "   - SMILES の最大長、バッチサイズ、学習率などを決める。\n",
        "2. **SMILES 文字ごとの出現回数を記録**\n",
        "   - `vocab_freq` を作成し、どの文字がどれだけ使われているかをカウント。\n",
        "3. **語彙リストを作成**\n",
        "   - `vocab` を作り、ニューラルネットの入力に必要な次元 `N_INPUT` を計算。\n",
        "\n",
        "この前処理を行うことで、SMILES を扱う機械学習モデルに適したデータを準備できます！"
      ],
      "metadata": {
        "id": "IHPtWBEqyt9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def smile2vec(vocab, vecsize, smile):\n",
        "    vec = []\n",
        "    for i in range(vecsize):\n",
        "        v = [0 for _ in range(len(vocab))]\n",
        "        if i < len(smile):\n",
        "            v[vocab.index(smile[i])] = 1\n",
        "        vec += v\n",
        "    return vec\n",
        "\n",
        "\n",
        "X = np.array([smile2vec(vocab, SMILES_MAXLEN, smile) for smile in list(property_df[SMILES_COL])])\n",
        "X_tensor = torch.from_numpy(X).float()\n",
        "dataset = TensorDataset(X_tensor)\n",
        "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "eX7gynrg_oDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、**SMILES（分子の文字列表現）を数値ベクトルに変換し、それを PyTorch の `DataLoader` に格納する**ための処理を行っています。主に以下のステップで構成されています。\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの解説**\n",
        "\n",
        "### **1. 必要なライブラリのインポート**\n",
        "```python\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "```\n",
        "- **`numpy`**: データの変換に使用。\n",
        "- **`torch`**: PyTorch のテンソル操作に使用。\n",
        "- **`TensorDataset`**: PyTorch でデータセットを作成するためのクラス。\n",
        "- **`DataLoader`**: データをバッチごとに処理し、シャッフルなどを適用するためのクラス。\n",
        "\n",
        "---\n",
        "\n",
        "### **2. SMILES をベクトルに変換する関数**\n",
        "```python\n",
        "def smile2vec(vocab, vecsize, smile):\n",
        "    vec = []\n",
        "    for i in range(vecsize):\n",
        "        v = [0 for _ in range(len(vocab))]  # 語彙サイズの長さを持つ 0 ベクトルを作成\n",
        "        if i < len(smile):  # SMILES 文字列の長さを超えない範囲で\n",
        "            v[vocab.index(smile[i])] = 1  # 文字を one-hot encoding\n",
        "        vec += v  # フラットなリストとして格納\n",
        "    return vec\n",
        "```\n",
        "#### **この関数の処理**\n",
        "- **`vocab`**: SMILES に含まれるユニークな文字のリスト。\n",
        "- **`vecsize`**: ベクトルの最大長（`SMILES_MAXLEN`）。\n",
        "- **`smile`**: 入力の SMILES 文字列。\n",
        "\n",
        "#### **処理の流れ**\n",
        "1. `vec = []` を用意（ベクトルを格納するリスト）。\n",
        "2. `vecsize` の長さ (`SMILES_MAXLEN` など) だけループする。\n",
        "3. `vocab` のサイズと同じ長さの 0 ベクトル `v` を作成。\n",
        "4. 文字列 `smile` の範囲内なら、その文字の位置を 1 にする（**one-hot encoding**）。\n",
        "5. `v` を `vec` に追加（フラットなリストとして格納）。\n",
        "\n",
        "#### **例**\n",
        "```python\n",
        "vocab = ['C', 'O', 'N', '=', '(']\n",
        "smile = \"COO\"\n",
        "vecsize = 5\n",
        "smile2vec(vocab, vecsize, smile)\n",
        "```\n",
        "- `C` → `[1, 0, 0, 0, 0]`\n",
        "- `O` → `[0, 1, 0, 0, 0]`\n",
        "- `O` → `[0, 1, 0, 0, 0]`\n",
        "- パディング部分 → `[0, 0, 0, 0, 0]`\n",
        "- **結果**\n",
        "```python\n",
        "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "```\n",
        "このように、**SMILES を固定長のベクトルに変換**する。\n",
        "\n",
        "---\n",
        "\n",
        "### **3. SMILES データをベクトル化**\n",
        "```python\n",
        "X = np.array([smile2vec(vocab, SMILES_MAXLEN, smile) for smile in list(property_df[SMILES_COL])])\n",
        "```\n",
        "- **`property_df[SMILES_COL]`** に含まれるすべての SMILES を `smile2vec()` に適用。\n",
        "- `numpy.array()` を使い、リストを NumPy 配列に変換。\n",
        "\n",
        "---\n",
        "\n",
        "### **4. NumPy 配列を PyTorch のテンソルに変換**\n",
        "```python\n",
        "X_tensor = torch.from_numpy(X).float()\n",
        "```\n",
        "- `torch.from_numpy(X)` によって NumPy 配列を PyTorch のテンソルに変換。\n",
        "- `.float()` を適用し、データ型を `float32` に変換（PyTorch のモデルは `float32` を使用することが多いため）。\n",
        "\n",
        "---\n",
        "\n",
        "### **5. PyTorch のデータセットとデータローダーの作成**\n",
        "```python\n",
        "dataset = TensorDataset(X_tensor)\n",
        "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "```\n",
        "- `TensorDataset(X_tensor)` を作成（`X_tensor` を PyTorch のデータセット形式に変換）。\n",
        "- `DataLoader()` を用いて、データセットをバッチごとに分割し、シャッフルを適用。\n",
        "  - **`batch_size=BATCH_SIZE`**: バッチサイズ（例: 16）。\n",
        "  - **`shuffle=True`**: データをランダムに並び替え（学習のバイアスを防ぐ）。\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの目的**\n",
        "このコードは、**SMILES 文字列をニューラルネットワークで扱いやすい形式（固定長ベクトル）に変換し、PyTorch の `DataLoader` を使ってバッチ処理を可能にする**ことが目的です。\n",
        "\n",
        "### **流れを整理**\n",
        "1. **SMILES を one-hot ベクトルに変換**（`smile2vec()`）。\n",
        "2. **NumPy 配列に変換**。\n",
        "3. **PyTorch のテンソルに変換**。\n",
        "4. **データセットとデータローダーを作成**。\n",
        "\n",
        "---\n",
        "\n",
        "## **応用**\n",
        "この手法は、**深層学習モデル（例えば RNN, Transformer, VAE）を用いた分子生成・特性予測** に利用できます。\n",
        "- **VAE（Variational Autoencoder）**: SMILES を潜在空間に圧縮し、新しい分子を生成。\n",
        "- **RNN（Recurrent Neural Network）**: SMILES の時系列データとしての性質を活かし、分子の特性を予測。\n",
        "- **Transformer**: より高性能な分子表現を学習し、分子の生成や特性予測を行う。\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "- `smile2vec()` で **SMILES を one-hot ベクトル化**。\n",
        "- NumPy 配列に変換し、**PyTorch のテンソルに変換**。\n",
        "- `TensorDataset` と `DataLoader` を用いて、**ミニバッチ学習が可能なデータローダーを作成**。\n",
        "- **ニューラルネットワークの入力データを準備する前処理**として非常に重要。\n",
        "\n",
        "この手法を応用すれば、SMILES から深層学習を用いた分子生成・特性予測が可能になります！"
      ],
      "metadata": {
        "id": "EiH2FgGOy7e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4NTuQ-I_x8F",
        "outputId": "a367128d-b4a0-4665-95ba-73c96ccdd4de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.1.0)\n",
            "Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2024.9.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、Python のパッケージマネージャー `pip` を使用して **RDKit** をインストールするためのコマンドです。  \n",
        "\n",
        "```python\n",
        "!pip install rdkit\n",
        "```\n",
        "- **`!`（エクスクラメーションマーク）**  \n",
        "  - Jupyter Notebook や Google Colab などの環境では、`!` を先頭につけることで、Python ではなく **シェルコマンド**（ターミナルで実行するコマンド）を実行できます。\n",
        "  - つまり、`pip install rdkit` というシェルコマンドを Python の環境から実行している。\n",
        "\n",
        "- **`pip install rdkit`**  \n",
        "  - `pip` は Python のパッケージ管理ツールで、外部ライブラリのインストールに使用。\n",
        "  - `rdkit` は、化学情報学（ケモインフォマティクス）のための Python ライブラリで、分子の構造解析やシミュレーションに利用される。\n",
        "\n",
        "---\n",
        "\n",
        "## **RDKit とは？**\n",
        "**RDKit（The Open-Source Cheminformatics Toolkit）** は、**化学情報学**（Chemoinformatics）に特化したオープンソースのツールキットです。  \n",
        "このライブラリを使うことで、以下のような処理が可能になります。\n",
        "\n",
        "### **主な機能**\n",
        "1. **SMILES（分子表記）と分子構造の変換**\n",
        "   ```python\n",
        "   from rdkit import Chem\n",
        "   mol = Chem.MolFromSmiles('CCO')  # エタノールの分子構造を作成\n",
        "   print(mol)\n",
        "   ```\n",
        "   → SMILES から分子オブジェクトを生成。\n",
        "\n",
        "2. **分子の可視化**\n",
        "   ```python\n",
        "   from rdkit.Chem import Draw\n",
        "   Draw.MolToImage(mol)\n",
        "   ```\n",
        "   → 分子の構造式を描画。\n",
        "\n",
        "3. **分子の特徴量抽出**\n",
        "   ```python\n",
        "   from rdkit.Chem import Descriptors\n",
        "   mw = Descriptors.MolWt(mol)  # 分子量を計算\n",
        "   print(mw)\n",
        "   ```\n",
        "   → 分子量や LogP（脂溶性）などの計算。\n",
        "\n",
        "4. **分子のフィンガープリント（分子の特徴を数値ベクトルに変換）**\n",
        "   ```python\n",
        "   from rdkit.Chem import rdMolDescriptors\n",
        "   fp = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024)\n",
        "   print(fp)\n",
        "   ```\n",
        "   → 分子を機械学習で扱うために、数値ベクトル（フィンガープリント）に変換。\n",
        "\n",
        "---\n",
        "\n",
        "## **RDKit のインストール時の注意点**\n",
        "1. **Google Colab の場合**\n",
        "   - `rdkit` は通常の `pip install` では動作しないことがあるため、以下のように `conda` を使うのが一般的：\n",
        "     ```python\n",
        "     !conda install -c conda-forge rdkit -y\n",
        "     ```\n",
        "   - もしくは、Colab では以下の方法も推奨される：\n",
        "     ```python\n",
        "     !pip install rdkit-pypi\n",
        "     ```\n",
        "\n",
        "2. **ローカル環境（Windows / Mac）**\n",
        "   - 公式サイト（https://www.rdkit.org/）にある手順に従って **Anaconda 環境** でのインストールが推奨される。\n",
        "   - 例：\n",
        "     ```bash\n",
        "     conda install -c conda-forge rdkit\n",
        "     ```\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "- `!pip install rdkit` は、RDKit を Python 環境にインストールするコマンド。\n",
        "- RDKit は **SMILES の処理、分子の可視化、特徴量抽出** などが可能な **化学情報学のライブラリ**。\n",
        "- Google Colab では `!pip install rdkit-pypi` や `!conda install -c conda-forge rdkit` が推奨されることがある。\n",
        "\n",
        "RDKit を使えば、機械学習による分子設計や特性予測などが可能になります！ 🚀"
      ],
      "metadata": {
        "id": "ZDNlUsPbzFAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "\n",
        "def get_best_smile(out_tensor):\n",
        "    best_smile = \"\"\n",
        "    for vec in out_tensor:\n",
        "        vec = vec.reshape(SMILES_MAXLEN, len(vocab))\n",
        "        smile = \"\".join([vocab[torch.argmax(v).item()] for v in vec])\n",
        "        mol = Chem.MolFromSmiles(smile)\n",
        "        while not mol:\n",
        "            if len(smile) == 0: break\n",
        "            smile = smile[:-1]\n",
        "            mol = Chem.MolFromSmiles(smile)\n",
        "\n",
        "        if len(best_smile) < len(smile):\n",
        "            best_smile = smile\n",
        "\n",
        "    return best_smile\n"
      ],
      "metadata": {
        "id": "JeCwS8As_sE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、**RDKit を使用してニューラルネットワークの出力テンソルを SMILES 文字列に変換し、最も妥当な SMILES（有効な化学構造）を取得する関数** `get_best_smile()` を定義しています。\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの解説**\n",
        "\n",
        "### **1. 必要なライブラリのインポート**\n",
        "```python\n",
        "from rdkit import Chem\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "```\n",
        "- `from rdkit import Chem`  \n",
        "  - RDKit の `Chem` モジュールをインポートし、分子構造の解析や変換に使用。\n",
        "- `from rdkit import RDLogger`\n",
        "  - RDKit の **ログ出力を制御** するためのモジュール。\n",
        "- `RDLogger.DisableLog('rdApp.*')`\n",
        "  - RDKit の警告ログを非表示にする（エラーメッセージを減らし、コードを見やすくする）。\n",
        "\n",
        "---\n",
        "\n",
        "### **2. `get_best_smile()` 関数の定義**\n",
        "```python\n",
        "def get_best_smile(out_tensor):\n",
        "```\n",
        "この関数は、**ニューラルネットワークの出力テンソル（`out_tensor`）を SMILES 文字列に変換し、有効な構造の中で最も長い SMILES を返す**。\n",
        "\n",
        "#### **引数**\n",
        "- `out_tensor`:  \n",
        "  - **モデルの出力テンソル**。  \n",
        "  - このテンソルは、one-hot エンコーディングされた SMILES に対応している。\n",
        "\n",
        "#### **返り値**\n",
        "- **最も長い有効な SMILES 文字列**。\n",
        "\n",
        "---\n",
        "\n",
        "### **3. 変数の初期化**\n",
        "```python\n",
        "best_smile = \"\"\n",
        "```\n",
        "- `best_smile` には **最も長い有効な SMILES 文字列** を格納。\n",
        "\n",
        "---\n",
        "\n",
        "### **4. テンソルを SMILES に変換**\n",
        "```python\n",
        "for vec in out_tensor:\n",
        "    vec = vec.reshape(SMILES_MAXLEN, len(vocab))\n",
        "    smile = \"\".join([vocab[torch.argmax(v).item()] for v in vec])\n",
        "```\n",
        "#### **処理の流れ**\n",
        "1. `out_tensor` の各要素 `vec` に対してループ。\n",
        "2. `vec.reshape(SMILES_MAXLEN, len(vocab))`  \n",
        "   - `vec` を (SMILES 文字列の最大長, 語彙サイズ) の形にリシェイプ。\n",
        "   - つまり、**SMILES 文字列の各文字が one-hot エンコーディングされた状態**になる。\n",
        "3. `torch.argmax(v).item()` を使って、**各位置で最も確率が高い（最大値を持つ）インデックスを取得**。\n",
        "4. `vocab` から対応する文字を取得して `smile` を作成。\n",
        "\n",
        "---\n",
        "\n",
        "### **5. 生成された SMILES が有効かチェック**\n",
        "```python\n",
        "mol = Chem.MolFromSmiles(smile)\n",
        "while not mol:\n",
        "    if len(smile) == 0: break\n",
        "    smile = smile[:-1]\n",
        "    mol = Chem.MolFromSmiles(smile)\n",
        "```\n",
        "- `Chem.MolFromSmiles(smile)`  \n",
        "  - **RDKit の関数**で、SMILES 文字列 `smile` から分子オブジェクト（`mol`）を生成。\n",
        "  - `mol` が `None` の場合、その SMILES は無効（化学的に正しくない）。\n",
        "- **無効な場合の処理**：\n",
        "  - `while not mol:` で無効な場合は、末尾の文字を削除（`smile = smile[:-1]`）。\n",
        "  - これを繰り返して **有効な SMILES になるまで修正**。\n",
        "  - `if len(smile) == 0: break` で、全削除される場合の対策。\n",
        "\n",
        "---\n",
        "\n",
        "### **6. 最も長い有効な SMILES を選択**\n",
        "```python\n",
        "if len(best_smile) < len(smile):\n",
        "    best_smile = smile\n",
        "```\n",
        "- 現在の `smile` の長さが、`best_smile` より長い場合、更新。\n",
        "- **最も長い有効な SMILES を保持**。\n",
        "\n",
        "---\n",
        "\n",
        "### **7. 最終的な SMILES を返す**\n",
        "```python\n",
        "return best_smile\n",
        "```\n",
        "- **最も長い有効な SMILES を関数の出力として返す**。\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの目的**\n",
        "- **ニューラルネットワークの出力テンソルを、適切な SMILES 文字列に変換**。\n",
        "- **無効な SMILES を修正し、最も長い有効な SMILES を選択**。\n",
        "\n",
        "---\n",
        "\n",
        "## **具体例**\n",
        "### **入力（`out_tensor`）**\n",
        "仮に `out_tensor` の 1 つの要素が次のような形だったとする：\n",
        "```python\n",
        "out_tensor[0] = [\n",
        "  [0, 1, 0, 0, 0],  # 'C'\n",
        "  [0, 0, 1, 0, 0],  # 'O'\n",
        "  [0, 0, 1, 0, 0],  # 'O'\n",
        "  [0, 0, 0, 0, 1],  # '('\n",
        "  [0, 0, 0, 0, 0],  # パディング\n",
        "]\n",
        "```\n",
        "対応する `vocab`:\n",
        "```python\n",
        "vocab = ['C', 'O', 'N', '=', '(']\n",
        "```\n",
        "### **処理**\n",
        "- `torch.argmax(v).item()` を使い、最も大きな値のインデックスを取得。\n",
        "- `vocab` を参照して `smile` を作成：\n",
        "  ```python\n",
        "  smile = \"COO(\"\n",
        "  ```\n",
        "- `Chem.MolFromSmiles(smile)` で **RDKit による分子のバリデーション**。\n",
        "  - `\"COO(\"` は無効なので、`\"COO\"` まで削除し、`mol` が作成可能な形にする。\n",
        "\n",
        "### **最終出力**\n",
        "`best_smile = \"COO\"`\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "- **`out_tensor` を SMILES 文字列に変換**：\n",
        "  - **one-hot ベクトル → SMILES 文字列** にデコード。\n",
        "- **無効な SMILES を修正**：\n",
        "  - RDKit (`Chem.MolFromSmiles()`) を使い、無効な構造を削除。\n",
        "- **最も長い有効な SMILES を返す**：\n",
        "  - ニューラルネットワークが生成する SMILES から **最も良い分子表現を取得**。\n",
        "\n",
        "この関数は **分子生成モデル（例：VAE, GAN）** などで、**生成された SMILES をクリーンな形式に変換する際に役立つ**！ 🚀"
      ],
      "metadata": {
        "id": "DCEw67AazStR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(torch.nn.Module):\n",
        "    def __init__(self, n_input=784, n_hidden=400, n_z=20):\n",
        "        super(VAE, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(n_input, n_hidden)\n",
        "        self.fc2 = torch.nn.Linear(n_hidden, n_z)\n",
        "        self.fc3 = torch.nn.Linear(n_hidden, n_z)\n",
        "        self.fc4 = torch.nn.Linear(n_z, n_hidden)\n",
        "        self.fc5 = torch.nn.Linear(n_hidden, n_input)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = torch.nn.functional.relu(self.fc1(x))\n",
        "        return self.fc2(h), self.fc3(h)\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(log_var/2)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = torch.nn.functional.relu(self.fc4(z))\n",
        "        return torch.sigmoid(self.fc5(h))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encode(x)\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        x_reconst = self.decode(z)\n",
        "        return x_reconst, mu, log_var"
      ],
      "metadata": {
        "id": "LbgkNoTd_w99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、**変分オートエンコーダ（VAE: Variational Autoencoder）** を PyTorch で実装したものです。  \n",
        "VAE は、データを圧縮（エンコード）し、潜在空間で表現を学習しながら、新しいデータを生成（デコード）するためのニューラルネットワークです。\n",
        "\n",
        "---\n",
        "\n",
        "## **クラスの概要**\n",
        "```python\n",
        "class VAE(torch.nn.Module):\n",
        "```\n",
        "- PyTorch の `torch.nn.Module` を継承して、ニューラルネットワークモデルを定義。\n",
        "- **変分オートエンコーダ（VAE）** を構築。\n",
        "\n",
        "---\n",
        "\n",
        "## **1. `__init__()`（初期化関数）**\n",
        "```python\n",
        "def __init__(self, n_input=784, n_hidden=400, n_z=20):\n",
        "```\n",
        "- `n_input`: 入力の次元数（デフォルト: 784）  \n",
        "  - 例：`28×28` の画像（MNIST）の場合、784次元。\n",
        "- `n_hidden`: 隠れ層の次元数（デフォルト: 400）\n",
        "- `n_z`: 潜在変数（潜在ベクトル `z`）の次元数（デフォルト: 20）\n",
        "\n",
        "### **エンコーダ部分（Encoder）**\n",
        "```python\n",
        "self.fc1 = torch.nn.Linear(n_input, n_hidden)  # 入力 → 隠れ層\n",
        "self.fc2 = torch.nn.Linear(n_hidden, n_z)  # 潜在変数の平均（μ）\n",
        "self.fc3 = torch.nn.Linear(n_hidden, n_z)  # 潜在変数の対数分散（log(σ²)）\n",
        "```\n",
        "- `fc1`: 入力データを `n_hidden` の次元に変換する全結合層（Encoder の隠れ層）。\n",
        "- `fc2`: **潜在変数の平均** `μ` を出力。\n",
        "- `fc3`: **潜在変数の対数分散** `log(σ²)` を出力。\n",
        "\n",
        "### **デコーダ部分（Decoder）**\n",
        "```python\n",
        "self.fc4 = torch.nn.Linear(n_z, n_hidden)  # 潜在変数 → 隠れ層\n",
        "self.fc5 = torch.nn.Linear(n_hidden, n_input)  # 隠れ層 → 再構成データ\n",
        "```\n",
        "- `fc4`: 潜在変数 `z` を `n_hidden` の次元に変換する全結合層。\n",
        "- `fc5`: `n_hidden` を `n_input` に変換し、元のデータを復元。\n",
        "\n",
        "---\n",
        "\n",
        "## **2. `encode()`（エンコーダ）**\n",
        "```python\n",
        "def encode(self, x):\n",
        "    h = torch.nn.functional.relu(self.fc1(x))\n",
        "    return self.fc2(h), self.fc3(h)\n",
        "```\n",
        "- `x` をエンコーダに通して、隠れ層を計算（`fc1` → ReLU 活性化関数）。\n",
        "- **潜在変数の平均 (`μ`) と対数分散 (`log_var`) を出力**。\n",
        "\n",
        "---\n",
        "\n",
        "## **3. `reparameterize()`（再パラメータ化トリック）**\n",
        "```python\n",
        "def reparameterize(self, mu, log_var):\n",
        "    std = torch.exp(log_var / 2)  # 分散の平方根（標準偏差）\n",
        "    eps = torch.randn_like(std)  # 標準正規分布からサンプリング\n",
        "    return mu + eps * std\n",
        "```\n",
        "- `log_var` を指数変換し、標準偏差 `std = exp(log_var/2)` を計算。\n",
        "- `torch.randn_like(std)` で標準正規分布 `N(0,1)` から乱数 `ε` をサンプリング。\n",
        "- **サンプリングした `ε` に `μ` を加え、最終的な `z` を作成**：\n",
        "  \\[\n",
        "  z = \\mu + \\epsilon \\cdot \\sigma\n",
        "  \\]\n",
        "  これを **再パラメータ化トリック（Reparameterization Trick）** と呼び、勾配計算を可能にする。\n",
        "\n",
        "---\n",
        "\n",
        "## **4. `decode()`（デコーダ）**\n",
        "```python\n",
        "def decode(self, z):\n",
        "    h = torch.nn.functional.relu(self.fc4(z))\n",
        "    return torch.sigmoid(self.fc5(h))\n",
        "```\n",
        "- `z` をデコーダに通して、元のデータの復元を試みる。\n",
        "- `fc4(z)` を `ReLU` で活性化。\n",
        "- `fc5` を通し、`sigmoid` 関数で出力（**値を 0 〜 1 に制約**）。\n",
        "\n",
        "---\n",
        "\n",
        "## **5. `forward()`（順伝播）**\n",
        "```python\n",
        "def forward(self, x):\n",
        "    mu, log_var = self.encode(x)  # 1. エンコーダ\n",
        "    z = self.reparameterize(mu, log_var)  # 2. 潜在変数のサンプリング\n",
        "    x_reconst = self.decode(z)  # 3. デコーダ\n",
        "    return x_reconst, mu, log_var  # 4. 再構成データと潜在変数を返す\n",
        "```\n",
        "1. **エンコーダで `μ` と `log_var` を計算**。\n",
        "2. **再パラメータ化トリックで `z` をサンプリング**。\n",
        "3. **デコーダで `z` から元データを復元**。\n",
        "4. **再構成データ `x_reconst`、`μ`、`log_var` を返す**。\n",
        "\n",
        "---\n",
        "\n",
        "## **VAE の全体像**\n",
        "### **エンコーダ（Encoder）**\n",
        "データ **x** を潜在空間の確率分布に変換：\n",
        "\\[\n",
        "q(z|x) = \\mathcal{N}(\\mu, \\sigma^2)\n",
        "\\]\n",
        "\n",
        "### **再パラメータ化**\n",
        "潜在変数 `z` をサンプリング：\n",
        "\\[\n",
        "z = \\mu + \\epsilon \\cdot \\sigma, \\quad \\epsilon \\sim \\mathcal{N}(0,1)\n",
        "\\]\n",
        "\n",
        "### **デコーダ（Decoder）**\n",
        "`z` から元データを復元：\n",
        "\\[\n",
        "p(x|z)\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "## **損失関数（VAE の学習）**\n",
        "通常のオートエンコーダとは異なり、**VAE では 2 つの損失を最小化**：\n",
        "1. **再構成誤差（MSE や BCE）**  \n",
        "   - `x_reconst` と `x` の誤差（ピクセルごとの違い）。\n",
        "2. **KL ダイバージェンス（正則化項）**  \n",
        "   - 潜在変数 `z` の分布を、標準正規分布 `N(0,1)` に近づける。\n",
        "\n",
        "損失関数：\n",
        "\\[\n",
        "\\mathcal{L} = \\text{Reconstruction Loss} + \\beta \\cdot D_{KL}(q(z|x) || p(z))\n",
        "\\]\n",
        "\\[\n",
        "D_{KL} = -\\frac{1}{2} \\sum_{i} \\left( 1 + \\log\\sigma_i^2 - \\mu_i^2 - \\sigma_i^2 \\right)\n",
        "\\]\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "- **VAE（変分オートエンコーダ）** を PyTorch で実装。\n",
        "- **`encode()`**: `x` を潜在変数の分布 `(μ, log_var)` に変換。\n",
        "- **`reparameterize()`**: `z = μ + εσ` を計算（再パラメータ化）。\n",
        "- **`decode()`**: `z` からデータを再構成。\n",
        "- **`forward()`**: エンコーダ → 潜在変数 → デコーダの流れを処理。\n",
        "\n",
        "この VAE を使うことで、**画像生成や分子生成（SMILES 文字列）** などの応用が可能！ 🚀"
      ],
      "metadata": {
        "id": "-WMvB8vOzfYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE(n_input=N_INPUT, n_hidden=N_HIDDEN, n_z=N_Z).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "losses = []\n",
        "reconst_losses = []\n",
        "kl_divs = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    for i, x in enumerate(data_loader):\n",
        "        x = x[0].to(device).view(-1, N_INPUT)\n",
        "        x_reconst, mu, log_var = model(x)\n",
        "\n",
        "        reconst_loss = torch.nn.functional.binary_cross_entropy(x_reconst, x, reduction='sum')\n",
        "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "\n",
        "        loss = reconst_loss + kl_div\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "        reconst_losses.append(reconst_loss.item())\n",
        "        kl_divs.append(kl_div.item())\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\"\n",
        "                   .format(epoch+1, NUM_EPOCHS, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(BATCH_SIZE, N_Z).to(device)\n",
        "        out = model.decode(z)\n",
        "        print(\"Epoch[{}/{}], Generated SMILES: {}\".format(epoch+1, NUM_EPOCHS, get_best_smile(out)))\n",
        "\n",
        "        # out, _, _ = model(x)\n",
        "        # print(\"Epoch[{}/{}], Reconstructed SMILES: {}\".format(epoch+1, NUM_EPOCHS, get_best_smile(out)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyt2UNMT_54N",
        "outputId": "3a0f1016-d2ae-4f54-f335-478bb1abc6c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[1/20], Step [100/548], Reconst Loss: 1398.6638, KL Div: 195.9709\n",
            "Epoch[1/20], Step [200/548], Reconst Loss: 1187.0525, KL Div: 130.9270\n",
            "Epoch[1/20], Step [300/548], Reconst Loss: 1116.9512, KL Div: 97.0856\n",
            "Epoch[1/20], Step [400/548], Reconst Loss: 901.8925, KL Div: 135.3994\n",
            "Epoch[1/20], Step [500/548], Reconst Loss: 752.6674, KL Div: 135.0882\n",
            "Epoch[1/20], Generated SMILES: O=NN([C@H](c1ccccc1)OC(=O)C)CC\n",
            "Epoch[2/20], Step [100/548], Reconst Loss: 716.5902, KL Div: 137.1727\n",
            "Epoch[2/20], Step [200/548], Reconst Loss: 715.3192, KL Div: 132.9384\n",
            "Epoch[2/20], Step [300/548], Reconst Loss: 772.6079, KL Div: 136.6139\n",
            "Epoch[2/20], Step [400/548], Reconst Loss: 833.4825, KL Div: 119.4229\n",
            "Epoch[2/20], Step [500/548], Reconst Loss: 741.7397, KL Div: 141.0988\n",
            "Epoch[2/20], Generated SMILES: O=NN([C@H](c1ccccc1)OC(=O)C)CC\n",
            "Epoch[3/20], Step [100/548], Reconst Loss: 777.6328, KL Div: 124.4297\n",
            "Epoch[3/20], Step [200/548], Reconst Loss: 740.7799, KL Div: 126.4378\n",
            "Epoch[3/20], Step [300/548], Reconst Loss: 679.2349, KL Div: 133.0582\n",
            "Epoch[3/20], Step [400/548], Reconst Loss: 799.8986, KL Div: 157.7232\n",
            "Epoch[3/20], Step [500/548], Reconst Loss: 696.3738, KL Div: 129.1851\n",
            "Epoch[3/20], Generated SMILES: O=NN([C@H](c1ccccc1)OC(=O)C)C\n",
            "Epoch[4/20], Step [100/548], Reconst Loss: 582.3895, KL Div: 148.2252\n",
            "Epoch[4/20], Step [200/548], Reconst Loss: 619.0645, KL Div: 167.8926\n",
            "Epoch[4/20], Step [300/548], Reconst Loss: 466.1190, KL Div: 148.9059\n",
            "Epoch[4/20], Step [400/548], Reconst Loss: 631.2424, KL Div: 164.0536\n",
            "Epoch[4/20], Step [500/548], Reconst Loss: 586.6461, KL Div: 170.5197\n",
            "Epoch[4/20], Generated SMILES: OCNN([C@H](c1ccccc1)OC(=O)C)C(CC=C)C\n",
            "Epoch[5/20], Step [100/548], Reconst Loss: 650.5941, KL Div: 180.7036\n",
            "Epoch[5/20], Step [200/548], Reconst Loss: 667.4292, KL Div: 196.9489\n",
            "Epoch[5/20], Step [300/548], Reconst Loss: 747.4022, KL Div: 188.2482\n",
            "Epoch[5/20], Step [400/548], Reconst Loss: 657.9269, KL Div: 194.8467\n",
            "Epoch[5/20], Step [500/548], Reconst Loss: 451.3973, KL Div: 190.0682\n",
            "Epoch[5/20], Generated SMILES: O=NN([C@H](c1ccccc1)OC(=O)C)CCCCCCO\n",
            "Epoch[6/20], Step [100/548], Reconst Loss: 577.3550, KL Div: 187.2087\n",
            "Epoch[6/20], Step [200/548], Reconst Loss: 539.8162, KL Div: 198.6595\n",
            "Epoch[6/20], Step [300/548], Reconst Loss: 344.4143, KL Div: 172.8326\n",
            "Epoch[6/20], Step [400/548], Reconst Loss: 466.6997, KL Div: 172.1282\n",
            "Epoch[6/20], Step [500/548], Reconst Loss: 549.3078, KL Div: 228.4567\n",
            "Epoch[6/20], Generated SMILES: O=NN([C@H](c1ccccc1)OC(=O)C)CC\n",
            "Epoch[7/20], Step [100/548], Reconst Loss: 419.6418, KL Div: 185.4391\n",
            "Epoch[7/20], Step [200/548], Reconst Loss: 620.4340, KL Div: 206.2026\n",
            "Epoch[7/20], Step [300/548], Reconst Loss: 452.1833, KL Div: 223.8744\n",
            "Epoch[7/20], Step [400/548], Reconst Loss: 335.3499, KL Div: 178.4720\n",
            "Epoch[7/20], Step [500/548], Reconst Loss: 584.0041, KL Div: 202.4354\n",
            "Epoch[7/20], Generated SMILES: O=NN([C@H](c1ccccc1)OC(=O)C)C\n",
            "Epoch[8/20], Step [100/548], Reconst Loss: 582.8287, KL Div: 226.1819\n",
            "Epoch[8/20], Step [200/548], Reconst Loss: 593.9325, KL Div: 231.4707\n",
            "Epoch[8/20], Step [300/548], Reconst Loss: 337.5399, KL Div: 205.2401\n",
            "Epoch[8/20], Step [400/548], Reconst Loss: 408.0938, KL Div: 186.0291\n",
            "Epoch[8/20], Step [500/548], Reconst Loss: 396.7779, KL Div: 206.0632\n",
            "Epoch[8/20], Generated SMILES: O=NN([C@H](c1ccccc1)OC(=O)C)C\n",
            "Epoch[9/20], Step [100/548], Reconst Loss: 561.5725, KL Div: 191.8885\n",
            "Epoch[9/20], Step [200/548], Reconst Loss: 433.7368, KL Div: 222.3448\n",
            "Epoch[9/20], Step [300/548], Reconst Loss: 542.8738, KL Div: 247.2856\n",
            "Epoch[9/20], Step [400/548], Reconst Loss: 436.4664, KL Div: 218.7750\n",
            "Epoch[9/20], Step [500/548], Reconst Loss: 337.8211, KL Div: 201.0217\n",
            "Epoch[9/20], Generated SMILES: CC(CCCCC(OC(=O)CCC)C)CCCCC\n",
            "Epoch[10/20], Step [100/548], Reconst Loss: 390.4310, KL Div: 222.6516\n",
            "Epoch[10/20], Step [200/548], Reconst Loss: 584.1205, KL Div: 235.1131\n",
            "Epoch[10/20], Step [300/548], Reconst Loss: 403.3398, KL Div: 232.2830\n",
            "Epoch[10/20], Step [400/548], Reconst Loss: 547.1742, KL Div: 241.6980\n",
            "Epoch[10/20], Step [500/548], Reconst Loss: 263.0607, KL Div: 192.0698\n",
            "Epoch[10/20], Generated SMILES: O=NN([C@H](c1ccccc1)OC(=O)C)CC\n",
            "Epoch[11/20], Step [100/548], Reconst Loss: 426.7264, KL Div: 212.0336\n",
            "Epoch[11/20], Step [200/548], Reconst Loss: 494.1588, KL Div: 228.5589\n",
            "Epoch[11/20], Step [300/548], Reconst Loss: 563.6962, KL Div: 241.5271\n",
            "Epoch[11/20], Step [400/548], Reconst Loss: 418.3508, KL Div: 233.3994\n",
            "Epoch[11/20], Step [500/548], Reconst Loss: 554.8713, KL Div: 249.6433\n",
            "Epoch[11/20], Generated SMILES: OCNN([C@H](c1ccccc1)OC(=O)C)CC\n",
            "Epoch[12/20], Step [100/548], Reconst Loss: 268.9211, KL Div: 181.5146\n",
            "Epoch[12/20], Step [200/548], Reconst Loss: 419.1240, KL Div: 257.3894\n",
            "Epoch[12/20], Step [300/548], Reconst Loss: 459.0175, KL Div: 217.1260\n",
            "Epoch[12/20], Step [400/548], Reconst Loss: 467.7155, KL Div: 218.9758\n",
            "Epoch[12/20], Step [500/548], Reconst Loss: 460.1293, KL Div: 226.0985\n",
            "Epoch[12/20], Generated SMILES: O=NN([C@H](c1ccccc1)OC(=O)C)C\n",
            "Epoch[13/20], Step [100/548], Reconst Loss: 306.3512, KL Div: 236.4096\n",
            "Epoch[13/20], Step [200/548], Reconst Loss: 396.0309, KL Div: 245.3425\n",
            "Epoch[13/20], Step [300/548], Reconst Loss: 685.6556, KL Div: 287.1401\n",
            "Epoch[13/20], Step [400/548], Reconst Loss: 443.8145, KL Div: 230.6732\n",
            "Epoch[13/20], Step [500/548], Reconst Loss: 395.7012, KL Div: 255.6785\n",
            "Epoch[13/20], Generated SMILES: CCC(N(CC(C(=O)CCNC=O)CN/O)C)CC#C\n",
            "Epoch[14/20], Step [100/548], Reconst Loss: 362.4291, KL Div: 222.6479\n",
            "Epoch[14/20], Step [200/548], Reconst Loss: 369.2656, KL Div: 229.4013\n",
            "Epoch[14/20], Step [300/548], Reconst Loss: 438.1568, KL Div: 253.3520\n",
            "Epoch[14/20], Step [400/548], Reconst Loss: 392.4444, KL Div: 225.9138\n",
            "Epoch[14/20], Step [500/548], Reconst Loss: 429.9651, KL Div: 255.2258\n",
            "Epoch[14/20], Generated SMILES: O=NN([C@H](c1ccccc1)OC(=O)C)C\n",
            "Epoch[15/20], Step [100/548], Reconst Loss: 460.5861, KL Div: 245.4408\n",
            "Epoch[15/20], Step [200/548], Reconst Loss: 407.7913, KL Div: 226.8909\n",
            "Epoch[15/20], Step [300/548], Reconst Loss: 274.7254, KL Div: 222.8801\n",
            "Epoch[15/20], Step [400/548], Reconst Loss: 362.2717, KL Div: 213.2890\n",
            "Epoch[15/20], Step [500/548], Reconst Loss: 423.7657, KL Div: 254.0321\n",
            "Epoch[15/20], Generated SMILES: O=NN([C@H](c1ccccc1)OC(=O)C)CC#N\n",
            "Epoch[16/20], Step [100/548], Reconst Loss: 437.8947, KL Div: 257.5851\n",
            "Epoch[16/20], Step [200/548], Reconst Loss: 407.3856, KL Div: 236.6258\n",
            "Epoch[16/20], Step [300/548], Reconst Loss: 327.5867, KL Div: 237.2969\n",
            "Epoch[16/20], Step [400/548], Reconst Loss: 474.3399, KL Div: 259.3527\n",
            "Epoch[16/20], Step [500/548], Reconst Loss: 330.1131, KL Div: 233.3517\n",
            "Epoch[16/20], Generated SMILES: O=NN([C@H](c1ccccc1)OC(=O)C)CC#CCOC\n",
            "Epoch[17/20], Step [100/548], Reconst Loss: 319.1153, KL Div: 222.9478\n",
            "Epoch[17/20], Step [200/548], Reconst Loss: 392.5114, KL Div: 256.3507\n",
            "Epoch[17/20], Step [300/548], Reconst Loss: 331.3054, KL Div: 237.8347\n",
            "Epoch[17/20], Step [400/548], Reconst Loss: 335.1343, KL Div: 272.2690\n",
            "Epoch[17/20], Step [500/548], Reconst Loss: 282.9572, KL Div: 231.4636\n",
            "Epoch[17/20], Generated SMILES: O=NN([C@H](c1ccccc1)OC(=O)C)C\n",
            "Epoch[18/20], Step [100/548], Reconst Loss: 493.7925, KL Div: 282.2801\n",
            "Epoch[18/20], Step [200/548], Reconst Loss: 387.7266, KL Div: 227.9608\n",
            "Epoch[18/20], Step [300/548], Reconst Loss: 346.8978, KL Div: 266.9726\n",
            "Epoch[18/20], Step [400/548], Reconst Loss: 408.7022, KL Div: 282.6780\n",
            "Epoch[18/20], Step [500/548], Reconst Loss: 425.8998, KL Div: 259.1453\n",
            "Epoch[18/20], Generated SMILES: O=NN([C@H](c1ccccc1)OC(=O)C)CCOC\n",
            "Epoch[19/20], Step [100/548], Reconst Loss: 426.8283, KL Div: 292.0031\n",
            "Epoch[19/20], Step [200/548], Reconst Loss: 370.3400, KL Div: 295.5953\n",
            "Epoch[19/20], Step [300/548], Reconst Loss: 382.2887, KL Div: 243.0010\n",
            "Epoch[19/20], Step [400/548], Reconst Loss: 304.2508, KL Div: 213.5022\n",
            "Epoch[19/20], Step [500/548], Reconst Loss: 366.3631, KL Div: 256.5172\n",
            "Epoch[19/20], Generated SMILES: O=NN([C@H](c1ccccc1)OC(=O)C)CC#N\n",
            "Epoch[20/20], Step [100/548], Reconst Loss: 380.2151, KL Div: 252.8343\n",
            "Epoch[20/20], Step [200/548], Reconst Loss: 419.3739, KL Div: 274.0258\n",
            "Epoch[20/20], Step [300/548], Reconst Loss: 391.7774, KL Div: 257.3960\n",
            "Epoch[20/20], Step [400/548], Reconst Loss: 324.7075, KL Div: 249.1904\n",
            "Epoch[20/20], Step [500/548], Reconst Loss: 561.9766, KL Div: 341.8622\n",
            "Epoch[20/20], Generated SMILES: O=C(Nc2c(ccccccccccccc1c2)C)C1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、**変分オートエンコーダ（VAE）** の学習と SMILES 文字列の生成を行う部分です。  \n",
        "具体的には、以下の流れで処理が進みます：\n",
        "\n",
        "1. **モデルと最適化手法の設定**\n",
        "2. **学習ループ（エポックごとにミニバッチで学習）**\n",
        "3. **損失（再構成誤差 + KL ダイバージェンス）の計算**\n",
        "4. **逆伝播とパラメータ更新**\n",
        "5. **定期的に生成した SMILES 文字列を表示**\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの詳細解説**\n",
        "\n",
        "### **1. モデルの作成と最適化手法の設定**\n",
        "```python\n",
        "model = VAE(n_input=N_INPUT, n_hidden=N_HIDDEN, n_z=N_Z).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "```\n",
        "- `VAE` モデルのインスタンスを作成し、**GPU（または CPU）に送る** (`to(device)`)。\n",
        "- **Adam** 最適化アルゴリズムを使用し、学習率 `LEARNING_RATE` でモデルのパラメータを更新。\n",
        "\n",
        "---\n",
        "\n",
        "### **2. 損失を記録するリストの作成**\n",
        "```python\n",
        "losses = []\n",
        "reconst_losses = []\n",
        "kl_divs = []\n",
        "```\n",
        "- **学習中の損失を記録するためのリスト** を用意：\n",
        "  - `losses` → **合計損失**（再構成誤差 + KL ダイバージェンス）\n",
        "  - `reconst_losses` → **再構成誤差**\n",
        "  - `kl_divs` → **KL ダイバージェンス**\n",
        "\n",
        "---\n",
        "\n",
        "### **3. エポックごとの学習ループ**\n",
        "```python\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "```\n",
        "- `NUM_EPOCHS` 回（例：20回）学習を繰り返す。\n",
        "\n",
        "---\n",
        "\n",
        "### **4. ミニバッチごとの学習処理**\n",
        "```python\n",
        "for i, x in enumerate(data_loader):\n",
        "```\n",
        "- `data_loader` からデータを **ミニバッチ** 単位で取得。\n",
        "- `x` はバッチサイズ `BATCH_SIZE` のデータを含む。\n",
        "\n",
        "```python\n",
        "x = x[0].to(device).view(-1, N_INPUT)\n",
        "```\n",
        "- `x[0]` を GPU に転送し、形状を `(BATCH_SIZE, N_INPUT)` に変形。\n",
        "\n",
        "---\n",
        "\n",
        "### **5. 順伝播（フォワードパス）**\n",
        "```python\n",
        "x_reconst, mu, log_var = model(x)\n",
        "```\n",
        "- モデルに `x` を入力し、\n",
        "  - **再構成データ `x_reconst`**\n",
        "  - **潜在変数の平均 `mu`**\n",
        "  - **潜在変数の対数分散 `log_var`**\n",
        "  を取得。\n",
        "\n",
        "---\n",
        "\n",
        "### **6. 損失関数の計算**\n",
        "```python\n",
        "reconst_loss = torch.nn.functional.binary_cross_entropy(x_reconst, x, reduction='sum')\n",
        "```\n",
        "- **再構成誤差（Reconstruction Loss）**  \n",
        "  - `x_reconst` と `x` の誤差を **バイナリークロスエントロピー（BCE）** で計算。\n",
        "  - `reduction='sum'` → バッチ全体の誤差を合計。\n",
        "\n",
        "```python\n",
        "kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "```\n",
        "- **KL ダイバージェンス（正則化項）**  \n",
        "  - VAE の潜在変数 `z` の分布 `q(z|x)` を標準正規分布 `p(z) ~ N(0,1)` に近づけるための項。\n",
        "  - 数式：\n",
        "    \\[\n",
        "    D_{KL} = -\\frac{1}{2} \\sum_{i} \\left( 1 + \\log\\sigma_i^2 - \\mu_i^2 - \\sigma_i^2 \\right)\n",
        "    \\]\n",
        "\n",
        "```python\n",
        "loss = reconst_loss + kl_div\n",
        "```\n",
        "- **最終的な損失（合計損失）**  \n",
        "  - 再構成誤差 `reconst_loss` と KL ダイバージェンス `kl_div` の合計。\n",
        "\n",
        "---\n",
        "\n",
        "### **7. 逆伝播とパラメータ更新**\n",
        "```python\n",
        "optimizer.zero_grad()  # 勾配の初期化\n",
        "loss.backward()  # 逆伝播\n",
        "optimizer.step()  # パラメータ更新\n",
        "```\n",
        "- **`zero_grad()`** → 前回の計算の勾配をクリア。\n",
        "- **`backward()`** → 誤差逆伝播（Backpropagation）。\n",
        "- **`step()`** → 最適化手法 `Adam` でパラメータを更新。\n",
        "\n",
        "---\n",
        "\n",
        "### **8. 損失の記録**\n",
        "```python\n",
        "losses.append(loss.item())\n",
        "reconst_losses.append(reconst_loss.item())\n",
        "kl_divs.append(kl_div.item())\n",
        "```\n",
        "- 計算した損失をリストに記録。\n",
        "\n",
        "---\n",
        "\n",
        "### **9. 100 バッチごとのログ表示**\n",
        "```python\n",
        "if (i+1) % 100 == 0:\n",
        "    print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\"\n",
        "           .format(epoch+1, NUM_EPOCHS, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))\n",
        "```\n",
        "- **100 バッチごとに学習の進捗を表示**。\n",
        "\n",
        "---\n",
        "\n",
        "### **10. 各エポック後に生成 SMILES を表示**\n",
        "```python\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(BATCH_SIZE, N_Z).to(device)  # 標準正規分布から潜在変数をサンプリング\n",
        "    out = model.decode(z)  # デコーダで新しいデータを生成\n",
        "    print(\"Epoch[{}/{}], Generated SMILES: {}\".format(epoch+1, NUM_EPOCHS, get_best_smile(out)))\n",
        "```\n",
        "- **`torch.no_grad()`**：勾配計算を無効化（メモリ節約）。\n",
        "- **`z = torch.randn(BATCH_SIZE, N_Z)`**：標準正規分布 `N(0,1)` から `z` をサンプリング。\n",
        "- **`model.decode(z)`**：デコーダで `z` から新しいデータ（SMILES）を生成。\n",
        "- **`get_best_smile(out)`**：最も良い SMILES 文字列を抽出し、表示。\n",
        "\n",
        "---\n",
        "\n",
        "## **コードのポイント**\n",
        "1. **VAE を用いて SMILES 文字列の学習を行う**\n",
        "2. **エンコーダで潜在変数 (`z`) の分布を学習**\n",
        "3. **デコーダで `z` からデータを生成**\n",
        "4. **損失関数は「再構成誤差 + KL ダイバージェンス」**\n",
        "5. **学習中に `z` から新しい SMILES 文字列を生成**\n",
        "\n",
        "---\n",
        "\n",
        "## **出力例**\n",
        "```\n",
        "Epoch[1/20], Step [100/500], Reconst Loss: 1567.2314, KL Div: 124.7845\n",
        "Epoch[1/20], Step [200/500], Reconst Loss: 1432.1208, KL Div: 98.5342\n",
        "...\n",
        "Epoch[1/20], Generated SMILES: C1CCCCC1O\n",
        "Epoch[2/20], Generated SMILES: CCOC(=O)C1=CC=CC=C1\n",
        "...\n",
        "```\n",
        "- 生成される **SMILES 文字列** は、学習が進むにつれてより化学的に意味のある構造になる。\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "- **変分オートエンコーダ（VAE）を使って SMILES を学習し、生成するコード**。\n",
        "- **再構成誤差（BCE）+ KL ダイバージェンス** を最小化することで、潜在空間を学習。\n",
        "- **学習中に `z` から SMILES を生成** し、化学分子の生成ができる。"
      ],
      "metadata": {
        "id": "nAa3dNaJzu_y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pYvX4KFJ_-Bi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}