{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **全コードのまとめ**\n",
        "\n",
        "このプロジェクトは、**SMILES 文字列**を用いて化学構造を表現するモデルを訓練し、**新しい SMILES 文字列を生成する**ことを目的としたものです。以下のステップで全体の流れを解説します。\n",
        "\n",
        "---\n",
        "\n",
        "### **1. 必要なライブラリのインポート**\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "```\n",
        "\n",
        "- **torch**：PyTorch（深層学習ライブラリ）を使用。\n",
        "- **pandas**：CSV ファイルの読み込みやデータの操作を行う。\n",
        "- **Counter**：単語の頻度カウントを行う。\n",
        "- **pickle**：学習した損失（Loss）の履歴を保存・読み込み。\n",
        "- **matplotlib.pyplot**：損失の履歴をグラフ化。\n",
        "- **random**：ランダムに開始テキストを選ぶ。\n",
        "\n",
        "---\n",
        "\n",
        "### **2. データセットの読み込みと処理**\n",
        "```python\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, url, smiles_col, sequence_length=4):\n",
        "        self.url = url\n",
        "        self.smiles_col = smiles_col\n",
        "        self.sequence_length = sequence_length\n",
        "        self.smiles = []\n",
        "        self.words = self.load_words()\n",
        "        self.uniq_words = self.get_uniq_words()\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
        "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "```\n",
        "\n",
        "- **Dataset クラス**：SMILES 文字列を読み込み、モデルが学習するために文字列をトークン化（単語のインデックス）する。\n",
        "- `sequence_length=4`：LSTM に渡す文字列の長さを設定（4文字ごとに学習）。\n",
        "\n",
        "---\n",
        "\n",
        "### **3. LSTM モデルの定義**\n",
        "\n",
        "```python\n",
        "class LSTM_Generator(torch.nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(LSTM_Generator, self).__init__()\n",
        "        self.lstm_size = 128\n",
        "        self.embedding_dim = 128\n",
        "        self.num_layers = 3\n",
        "\n",
        "        n_vocab = len(dataset.uniq_words)\n",
        "        self.embedding = torch.nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_size=self.lstm_size,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.2,\n",
        "        )\n",
        "        self.fc = torch.nn.Linear(self.lstm_size, n_vocab)\n",
        "```\n",
        "\n",
        "- **LSTM_Generator クラス**：LSTM モデルの構造を定義。\n",
        "  - **埋め込み層**：入力された単語（文字）をベクトル空間に変換。\n",
        "  - **LSTM 層**：時系列データ（文字列）を処理。\n",
        "  - **全結合層**：最終的に SMILES の各文字に対する予測を行う。\n",
        "\n",
        "---\n",
        "\n",
        "### **4. 学習処理**\n",
        "\n",
        "```python\n",
        "def train(dataset, model):\n",
        "    losses = []\n",
        "    model.train()\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    for epoch in range(MAX_EPOCHS):\n",
        "        state_h, state_c = model.init_state(SEQUENCE_LENGTH)\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "            loss = criterion(y_pred.transpose(1, 2), y)\n",
        "            total_loss += loss.item()\n",
        "            state_h = state_h.detach()\n",
        "            state_c = state_c.detach()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch: {epoch+1}, Loss: {total_loss:.3f}\")\n",
        "        losses.append(total_loss)\n",
        "\n",
        "    return losses\n",
        "```\n",
        "\n",
        "- **train() 関数**：LSTM モデルをトレーニング。\n",
        "  - **クロスエントロピー損失**：予測と実際の文字列の差を計算し、モデルを最適化。\n",
        "  - **Adam オプティマイザ**：勾配に基づいてモデルのパラメータを更新。\n",
        "\n",
        "---\n",
        "\n",
        "### **5. モデル評価と SMILES 生成**\n",
        "\n",
        "```python\n",
        "def predict(dataset, model, text, next_words=50):\n",
        "    words = [text[i] for i in range(len(text))]\n",
        "    model.eval()\n",
        "\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "\n",
        "    return \"\".join(words)\n",
        "```\n",
        "\n",
        "- **predict() 関数**：モデルに与えられたテキストから、次の文字を生成し、新しい SMILES 文字列を生成。\n",
        "  - 最初に与えた文字列（`text`）を基に **次の 50 文字**を予測。\n",
        "\n",
        "---\n",
        "\n",
        "### **6. 学習済みモデルの評価**\n",
        "\n",
        "```python\n",
        "generated_smiles = predict(dataset, model, text='C')\n",
        "print(generated_smiles)\n",
        "```\n",
        "\n",
        "- **SMILES 生成**：`'C'` という文字を初期入力として、新しい SMILES 文字列を生成。\n",
        "- 生成した SMILES 文字列を表示。\n",
        "\n",
        "---\n",
        "\n",
        "### **7. 損失履歴の可視化**\n",
        "\n",
        "```python\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss History')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "- 学習の損失（Loss）の履歴を **グラフ化** し、訓練中にモデルがどのように収束しているかを可視化。\n",
        "\n",
        "---\n",
        "\n",
        "### **8. 学習済みモデルと損失履歴の保存**\n",
        "\n",
        "```python\n",
        "torch.save(model.state_dict(), 'model_epoch200.pth')\n",
        "with open('losses_epoch200.pkl', 'wb') as f:\n",
        "    pickle.dump(losses, f)\n",
        "```\n",
        "\n",
        "- **モデルの保存**：学習済みのモデルを `.pth` ファイルとして保存。\n",
        "- **損失履歴の保存**：`pickle` を使い、学習の損失履歴を保存。\n",
        "\n",
        "---\n",
        "\n",
        "### **全体の流れ**\n",
        "\n",
        "1. **データセットの準備**：SMILES 文字列を読み込み、トークン化。\n",
        "2. **LSTM モデルの定義**：文字列生成用の LSTM モデルを設計。\n",
        "3. **モデルの学習**：データを使ってモデルを訓練し、損失を最小化。\n",
        "4. **モデル評価と生成**：学習後、初期の SMILES 文字列を基に新しい SMILES 文字列を生成。\n",
        "5. **損失の可視化**：学習過程をグラフ化し、収束状況を確認。\n",
        "\n",
        "---\n",
        "\n",
        "このプロジェクトは、化学構造を表現する SMILES 文字列を生成するモデルを学習し、新しい分子構造を生成するために利用できます！"
      ],
      "metadata": {
        "id": "y7R63JFlsBsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lKN1UVYMEUR",
        "outputId": "4edebd54-4a5a-4f0c-ea92-ca834a103e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.1.0)\n",
            "Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2024.9.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`!pip install rdkit` のコードは、Pythonのパッケージマネージャー `pip` を使用して **RDKit** というライブラリをインストールするためのコマンドです。  \n",
        "\n",
        "### **コードの解説**\n",
        "1. `!`（エクスクラメーションマーク）:\n",
        "   - Jupyter Notebook や Google Colab で実行する際に、シェルコマンド（ターミナルのコマンド）を実行するためのプレフィックスです。  \n",
        "   - 通常のPythonスクリプトでは不要で、代わりに `pip install rdkit` を使います。\n",
        "\n",
        "2. `pip install rdkit`:\n",
        "   - Pythonのパッケージ管理ツール `pip` を使って **RDKit** をインストールします。  \n",
        "   - **RDKit** は、化学情報学や分子モデリングに使用されるオープンソースのライブラリで、分子構造の解析、フィンガープリント生成、分子の可視化、化学的性質の計算などができます。\n",
        "\n",
        "### **補足**\n",
        "RDKitは通常の `pip install` では公式のPythonパッケージインデックス（PyPI）から直接インストールできないことが多く、代わりに **conda** を使ってインストールするのが一般的です。  \n",
        "したがって、環境によっては以下の方法を試す必要があります。\n",
        "\n",
        "#### **1. Condaを使ったインストール（推奨）**\n",
        "```sh\n",
        "conda install -c conda-forge rdkit\n",
        "```\n",
        "- `-c conda-forge` は、RDKitが提供されている `conda-forge` チャネルを指定するオプションです。\n",
        "\n",
        "#### **2. Google Colabでのインストール**\n",
        "Google Colabでは、以下のように `pip` ではなく `conda` を使う必要があります。\n",
        "```sh\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!conda install -c conda-forge rdkit -y\n",
        "```\n",
        "\n",
        "### **まとめ**\n",
        "- `!pip install rdkit` はJupyter NotebookでRDKitをインストールする試みだが、環境によっては `pip` ではなく `conda` の使用が推奨される。\n",
        "- RDKitは化学情報学や機械学習で分子構造を扱うのに便利なライブラリ。  \n",
        "- Google Colabでは `conda-forge` からのインストールが必要。\n",
        "\n",
        "RDKitを使って化学データを処理することに興味があるようですが、具体的にどのようなタスクに利用したいですか？"
      ],
      "metadata": {
        "id": "JudEreUQOB7i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd7aU41ML7va"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "\n",
        "def trim_smiles(smile):\n",
        "    mol = mol_from_smiles(smile)\n",
        "    while not mol:\n",
        "        if len(smile) == 0: break\n",
        "        smile = smile[:-1]\n",
        "        mol = mol_from_smiles(smile)\n",
        "    return smile\n",
        "\n",
        "\n",
        "def mol_from_smiles(smile):\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smile)\n",
        "        return mol\n",
        "    except:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、RDKit を使って **SMILES 文字列**（分子の構造を表す文字列）を検証し、無効な部分を削りながら有効な SMILES を見つける処理を行います。  \n",
        "\n",
        "---\n",
        "\n",
        "## **コードの詳細**\n",
        "### **1. `from rdkit import Chem`**\n",
        "RDKitの `Chem` モジュールをインポートします。  \n",
        "- `Chem.MolFromSmiles(smile)` を使うことで、**SMILES 文字列を分子オブジェクト（Mol）に変換**できます。  \n",
        "- もしSMILESが無効な場合、`MolFromSmiles` は `None` を返します。\n",
        "\n",
        "---\n",
        "\n",
        "### **2. `mol_from_smiles(smile)` 関数**\n",
        "この関数は、SMILES 文字列を **RDKit の分子オブジェクト** (`Mol`) に変換するラッパー関数です。\n",
        "\n",
        "```python\n",
        "def mol_from_smiles(smile):\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smile)\n",
        "        return mol\n",
        "    except:\n",
        "        return None\n",
        "```\n",
        "- `Chem.MolFromSmiles(smile)` を使ってSMILESを `Mol` オブジェクトに変換する。\n",
        "- 変換に失敗した場合（例外が発生した場合）、`None` を返す。\n",
        "\n",
        "> **注意**: `Chem.MolFromSmiles(smile)` は通常例外を投げず、無効なSMILESなら単に `None` を返します。  \n",
        "> したがって `try-except` はなくても問題ない場合が多いです。\n",
        "\n",
        "---\n",
        "\n",
        "### **3. `trim_smiles(smile)` 関数**\n",
        "この関数は、SMILES 文字列の末尾から1文字ずつ削除しながら、**有効なSMILES** を見つける処理を行います。\n",
        "\n",
        "```python\n",
        "def trim_smiles(smile):\n",
        "    mol = mol_from_smiles(smile)  # SMILESをMolに変換\n",
        "    while not mol:  # 無効な場合はループ\n",
        "        if len(smile) == 0:  # 空文字列になったら終了\n",
        "            break\n",
        "        smile = smile[:-1]  # 末尾を1文字削除\n",
        "        mol = mol_from_smiles(smile)  # 再度Molに変換\n",
        "    return smile  # 最後に有効なSMILESを返す\n",
        "```\n",
        "\n",
        "#### **処理の流れ**\n",
        "1. `mol_from_smiles(smile)` を使って SMILES を Mol に変換する。\n",
        "2. `Mol` オブジェクトが `None`（無効）なら、1文字ずつ削りながら再試行。\n",
        "3. 有効な SMILES になった時点でループ終了し、残った部分を返す。\n",
        "\n",
        "---\n",
        "\n",
        "## **動作例**\n",
        "### **入力例 1（有効なSMILES）**\n",
        "```python\n",
        "trim_smiles(\"CCO\")  # エタノール\n",
        "```\n",
        "- `\"CCO\"` は有効なSMILES → そのまま返す。\n",
        "- **出力:** `\"CCO\"`\n",
        "\n",
        "---\n",
        "\n",
        "### **入力例 2（無効なSMILESを含む）**\n",
        "```python\n",
        "trim_smiles(\"CCO123\")\n",
        "```\n",
        "1. `\"CCO123\"` → 無効\n",
        "2. `\"CCO12\"` → 無効\n",
        "3. `\"CCO1\"` → 無効\n",
        "4. `\"CCO\"` → **有効！**\n",
        "5. **出力:** `\"CCO\"`\n",
        "\n",
        "---\n",
        "\n",
        "## **用途**\n",
        "- **データクリーニング**:\n",
        "  - 無効なSMILESを取り除き、最大限有効な部分を抽出する。\n",
        "- **SMILESのフォーマットエラー修正**:\n",
        "  - 間違った文字を含む場合に、できるだけ修正して解析を進める。\n",
        "\n",
        "---\n",
        "\n",
        "## **改善点**\n",
        "### **1. `Chem.MolFromSmiles()` の `try-except` は不要**\n",
        "RDKit の `MolFromSmiles` は、無効な SMILES に対して `None` を返すため、 `try-except` はなくても問題ありません。\n",
        "\n",
        "### **2. `trim_smiles` の効率化**\n",
        "- 末尾を削除するのではなく、`Chem.MolFromSmiles` による部分一致を使う方法も考えられる。\n",
        "- 例えば、`Chem.SanitizeMol()` を使ってエラーをチェックしながら部分的に修正できる可能性がある。\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "- `trim_smiles(smile)` は、無効な SMILES の末尾を削りながら、有効な SMILES を探す関数。\n",
        "- `mol_from_smiles(smile)` は、SMILES を `Mol` オブジェクトに変換する関数。\n",
        "- RDKit を使って **化学データの前処理** や **エラーチェック** に役立つ。\n",
        "\n",
        "このコードをどのような用途で使おうと考えていますか？"
      ],
      "metadata": {
        "id": "PR-snf5PObNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, url, smiles_col, sequence_length=4):\n",
        "        self.url = url\n",
        "        self.smiles_col = smiles_col\n",
        "        self.sequence_length = sequence_length\n",
        "        self.smiles = []\n",
        "        self.words = self.load_words()\n",
        "        self.uniq_words = self.get_uniq_words()\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
        "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "\n",
        "    def load_words(self):\n",
        "        train_df = pd.read_csv(self.url)\n",
        "        self.smiles = list(train_df[self.smiles_col])\n",
        "        text = train_df[self.smiles_col].str.cat(sep=' ')\n",
        "        text = \"\".join(text.split(' '))\n",
        "        return [text[i] for i in range(len(text))]\n",
        "\n",
        "    def get_uniq_words(self):\n",
        "        word_counts = Counter(self.words)\n",
        "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words_indexes) - self.sequence_length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
        "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
        "        )"
      ],
      "metadata": {
        "id": "MZG9hNPWL-5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、SMILES 文字列を **時系列データ** として扱い、ニューラルネットワークの **データセット（PyTorch Dataset）** を作成するクラス `Dataset` を定義しています。  \n",
        "  \n",
        "### **コードの概要**\n",
        "- **SMILESデータの読み込み**\n",
        "- **各文字をトークンとして扱い、インデックスに変換**\n",
        "- **シーケンスデータを作成し、次の文字を予測する形式に変換**\n",
        "  \n",
        "**主な用途:**  \n",
        "このデータセットは、**SMILES 文字列を対象にした言語モデルの学習** に使用できます（例: RNN, LSTM, Transformer）。\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの詳細**\n",
        "### **1. 必要なライブラリのインポート**\n",
        "```python\n",
        "import torch\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "```\n",
        "- `torch`: PyTorchのデータセット作成とテンソル処理用\n",
        "- `pandas`: CSVデータの読み込み\n",
        "- `Counter`: 文字の出現頻度をカウントし、ユニークな文字リストを作成するために使用\n",
        "\n",
        "---\n",
        "\n",
        "### **2. `Dataset` クラス**\n",
        "PyTorch の `Dataset` クラスを継承して、独自のデータセットを定義。\n",
        "\n",
        "```python\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **3. `__init__` メソッド（初期化処理）**\n",
        "```python\n",
        "def __init__(self, url, smiles_col, sequence_length=4):\n",
        "```\n",
        "- `url`: CSVファイルのURLまたはパス\n",
        "- `smiles_col`: SMILES 文字列が含まれる列名\n",
        "- `sequence_length`: 1つのデータに含まれる文字列の長さ（デフォルトは4）\n",
        "\n",
        "**処理の流れ**\n",
        "```python\n",
        "self.smiles = []\n",
        "self.words = self.load_words()  # SMILES 文字列を1文字ごとにリスト化\n",
        "self.uniq_words = self.get_uniq_words()  # ユニークな文字のリストを取得\n",
        "```\n",
        "- `self.words`: SMILES 文字列を **1文字ごとのリスト** に変換  \n",
        "- `self.uniq_words`: 文字の種類をユニークにしたリスト（出現頻度順）\n",
        "\n",
        "```python\n",
        "self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
        "self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
        "```\n",
        "- **文字 → インデックス**\n",
        "- **インデックス → 文字** の辞書を作成\n",
        "\n",
        "```python\n",
        "self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "```\n",
        "- `self.words_indexes`: SMILES 文字を **インデックスのリスト** に変換\n",
        "\n",
        "---\n",
        "\n",
        "### **4. `load_words()`（SMILESを文字リストに変換）**\n",
        "```python\n",
        "def load_words(self):\n",
        "    train_df = pd.read_csv(self.url)  # CSVデータの読み込み\n",
        "    self.smiles = list(train_df[self.smiles_col])  # SMILESのリスト化\n",
        "    text = train_df[self.smiles_col].str.cat(sep=' ')  # SMILESを連結\n",
        "    text = \"\".join(text.split(' '))  # 空白を削除\n",
        "    return [text[i] for i in range(len(text))]  # 1文字ずつリスト化\n",
        "```\n",
        "**処理の流れ**\n",
        "1. CSVデータを `pandas` で読み込む\n",
        "2. 指定された列の SMILES をリストに保存\n",
        "3. すべての SMILES を結合し、**1つの長い文字列** にする\n",
        "4. 空白を削除\n",
        "5. 文字列を1文字ずつリストに変換\n",
        "\n",
        "**例**\n",
        "```python\n",
        "# CSVデータ\n",
        "smiles_col = [\"CCO\", \"C=O\", \"NCCO\"]\n",
        "# 結果\n",
        "text = \"CCOC=ONCCO\"\n",
        "words = [\"C\", \"C\", \"O\", \"C\", \"=\", \"O\", \"N\", \"C\", \"C\", \"O\"]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **5. `get_uniq_words()`（ユニークな文字を取得）**\n",
        "```python\n",
        "def get_uniq_words(self):\n",
        "    word_counts = Counter(self.words)  # 文字の頻度をカウント\n",
        "    return sorted(word_counts, key=word_counts.get, reverse=True)  # 出現頻度順にソート\n",
        "```\n",
        "- `Counter` で文字ごとの出現回数を取得\n",
        "- 出現回数の多い順にソートして、ユニークな文字リストを作成\n",
        "\n",
        "---\n",
        "\n",
        "### **6. `__len__()`（データセットの長さを取得）**\n",
        "```python\n",
        "def __len__(self):\n",
        "    return len(self.words_indexes) - self.sequence_length\n",
        "```\n",
        "- `self.words_indexes` の長さから `sequence_length` を引いたものがデータ数\n",
        "- 例えば `words_indexes = [0, 1, 2, 3, 4]` で `sequence_length=2` の場合:\n",
        "  - `len(words_indexes) = 5`\n",
        "  - `データ数 = 5 - 2 = 3`\n",
        "  - **データの組み合わせ**\n",
        "    1. `[0, 1] → [1, 2]`\n",
        "    2. `[1, 2] → [2, 3]`\n",
        "    3. `[2, 3] → [3, 4]`\n",
        "\n",
        "---\n",
        "\n",
        "### **7. `__getitem__()`（データの取得）**\n",
        "```python\n",
        "def __getitem__(self, index):\n",
        "    return (\n",
        "        torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
        "        torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
        "    )\n",
        "```\n",
        "- 入力データ: `index` から `index+sequence_length` までの文字インデックス\n",
        "- ラベルデータ: `index+1` から `index+sequence_length+1` までの文字インデックス\n",
        "\n",
        "**例**\n",
        "```python\n",
        "words_indexes = [0, 1, 2, 3, 4]\n",
        "sequence_length = 2\n",
        "\n",
        "index = 0\n",
        "入力データ:  [0, 1]\n",
        "ラベルデータ: [1, 2]\n",
        "\n",
        "index = 1\n",
        "入力データ:  [1, 2]\n",
        "ラベルデータ: [2, 3]\n",
        "```\n",
        "\n",
        "**用途**\n",
        "- **言語モデル（次の文字の予測）**\n",
        "- **RNN, LSTM, Transformer の学習データ**\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "| メソッド | 役割 |\n",
        "|----------|------|\n",
        "| `load_words()` | CSVからSMILESを取得し、1文字ずつリスト化 |\n",
        "| `get_uniq_words()` | 文字の出現頻度順でユニークなリストを作成 |\n",
        "| `__len__()` | データセットのサイズを返す |\n",
        "| `__getitem__()` | 入力とラベルのペアを作成（時系列データ） |\n",
        "\n",
        "**このデータセットは、SMILES 文字列を対象にした「次の文字を予測するモデル」に使えます。**  \n",
        "例えば、RNN や Transformer を用いた **SMILES 生成** モデルを作ることができます。  \n",
        "\n",
        "このコードをどのような用途に使おうと考えていますか？ 🚀"
      ],
      "metadata": {
        "id": "SUmOMvTMpgss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class LSTM_Generator(torch.nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(LSTM_Generator, self).__init__()\n",
        "        self.lstm_size = 128\n",
        "        self.embedding_dim = 128\n",
        "        self.num_layers = 3\n",
        "\n",
        "        n_vocab = len(dataset.uniq_words)\n",
        "        self.embedding = torch.nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_size=self.lstm_size,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.2,\n",
        "        )\n",
        "        self.fc = torch.nn.Linear(self.lstm_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.fc(output)\n",
        "\n",
        "        return logits, state\n",
        "\n",
        "    def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
        "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))\n"
      ],
      "metadata": {
        "id": "Br5BgNMUMHwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、**LSTM を用いた SMILES 文字列の生成モデル** を実装したものです。  \n",
        "PyTorch を使い、ニューラルネットワーク (`torch.nn.Module` のサブクラス) として `LSTM_Generator` を定義しています。  \n",
        "\n",
        "---\n",
        "\n",
        "## **コードの概要**\n",
        "| 要素 | 説明 |\n",
        "|------|------|\n",
        "| **モデルの目的** | SMILES の文字列生成（次の文字を予測する言語モデル） |\n",
        "| **入力データ** | SMILES 文字列のインデックス（整数配列） |\n",
        "| **出力データ** | 各時間ステップでの次の文字の確率分布 |\n",
        "| **使用する層** | 埋め込み層 (`Embedding`), LSTM (`LSTM`), 全結合層 (`Linear`) |\n",
        "| **学習対象** | SMILES の次の文字を予測するために LSTM を学習 |\n",
        "\n",
        "---\n",
        "\n",
        "## **1. `__init__()`（モデルの初期化）**\n",
        "```python\n",
        "class LSTM_Generator(torch.nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(LSTM_Generator, self).__init__()\n",
        "```\n",
        "- `torch.nn.Module` を継承してニューラルネットワークを定義。\n",
        "- `dataset` は `Dataset` クラスのインスタンス（データセットオブジェクト）。\n",
        "\n",
        "### **(1) ハイパーパラメータの設定**\n",
        "```python\n",
        "self.lstm_size = 128       # LSTMの隠れ層のサイズ\n",
        "self.embedding_dim = 128   # 埋め込み層の次元数\n",
        "self.num_layers = 3        # LSTMの層の数\n",
        "```\n",
        "- LSTMのサイズ (`hidden_size`) や層の数 (`num_layers`) を定義。\n",
        "\n",
        "### **(2) 語彙サイズ（n_vocab）の取得**\n",
        "```python\n",
        "n_vocab = len(dataset.uniq_words)\n",
        "```\n",
        "- `dataset.uniq_words` には、SMILES に登場する **ユニークな文字のリスト** が格納されている。\n",
        "- その長さを `n_vocab` として、**語彙サイズ（ユニークなトークンの数）** とする。\n",
        "\n",
        "### **(3) 埋め込み層（Embedding）**\n",
        "```python\n",
        "self.embedding = torch.nn.Embedding(\n",
        "    num_embeddings=n_vocab,\n",
        "    embedding_dim=self.embedding_dim,\n",
        ")\n",
        "```\n",
        "- `Embedding` 層は **文字（インデックス）をベクトルに変換** する層。\n",
        "- `num_embeddings=n_vocab`: 語彙のサイズ（文字の種類数）\n",
        "- `embedding_dim=self.embedding_dim`: 埋め込みベクトルの次元数（128）\n",
        "\n",
        "### **(4) LSTM層**\n",
        "```python\n",
        "self.lstm = torch.nn.LSTM(\n",
        "    input_size=self.lstm_size,  # 入力の特徴量の次元数\n",
        "    hidden_size=self.lstm_size,  # LSTMの隠れ状態の次元数\n",
        "    num_layers=self.num_layers,  # LSTMの層の数\n",
        "    dropout=0.2,                 # ドロップアウト率（過学習防止）\n",
        ")\n",
        "```\n",
        "- `LSTM` は**系列データを処理するRNNの一種**。\n",
        "- `input_size = self.lstm_size`: 入力の次元（通常 `embedding_dim` にすべきだが、`lstm_size` になっている）。\n",
        "- `hidden_size = self.lstm_size`: 隠れ層のサイズ。\n",
        "- `num_layers = self.num_layers`: LSTM の層数（3層）。\n",
        "- `dropout=0.2`: 過学習を防ぐためのドロップアウト（0.2 = 20%）。\n",
        "\n",
        "### **(5) 全結合層（Linear）**\n",
        "```python\n",
        "self.fc = torch.nn.Linear(self.lstm_size, n_vocab)\n",
        "```\n",
        "- `LSTM` の出力を、次の文字の確率分布（`n_vocab` のサイズ）に変換するための **全結合層**。\n",
        "\n",
        "---\n",
        "\n",
        "## **2. `forward()`（順伝播）**\n",
        "```python\n",
        "def forward(self, x, prev_state):\n",
        "```\n",
        "- `x`: **入力シーケンス（インデックスのテンソル）**\n",
        "- `prev_state`: **前の LSTM の隠れ状態（h, c）**\n",
        "\n",
        "### **(1) 埋め込み層でベクトル変換**\n",
        "```python\n",
        "embed = self.embedding(x)\n",
        "```\n",
        "- `x`（インデックスのテンソル）を `embedding` 層に通して、**埋め込みベクトル** に変換。\n",
        "- `embed.shape = (batch_size, sequence_length, embedding_dim)`\n",
        "\n",
        "### **(2) LSTM に入力**\n",
        "```python\n",
        "output, state = self.lstm(embed, prev_state)\n",
        "```\n",
        "- `embed` を LSTM に入力。\n",
        "- `output`: LSTM の出力（各時刻の隠れ状態）。\n",
        "- `state`: 次の時刻に渡す LSTM の内部状態 `(h, c)`。\n",
        "\n",
        "**出力の形状**\n",
        "- `output.shape = (batch_size, sequence_length, lstm_size)`\n",
        "\n",
        "### **(3) 全結合層を通して次の文字の確率を計算**\n",
        "```python\n",
        "logits = self.fc(output)\n",
        "```\n",
        "- `output` を `fc` 層に通し、各時刻での **次の文字のスコア（ロジット）** を計算。\n",
        "- `logits.shape = (batch_size, sequence_length, n_vocab)`\n",
        "\n",
        "### **(4) ロジットと状態を返す**\n",
        "```python\n",
        "return logits, state\n",
        "```\n",
        "- **`logits`（次の文字の確率分布）**\n",
        "- **`state`（次の時刻に渡す LSTM の隠れ状態）**\n",
        "\n",
        "---\n",
        "\n",
        "## **3. `init_state()`（LSTMの初期状態を作成）**\n",
        "```python\n",
        "def init_state(self, sequence_length):\n",
        "    return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
        "            torch.zeros(self.num_layers, sequence_length, self.lstm_size))\n",
        "```\n",
        "- LSTM の初期状態 `(h_0, c_0)` を **ゼロベクトル** で初期化。\n",
        "- `num_layers`: LSTM の層数\n",
        "- `sequence_length`: 入力のシーケンス長\n",
        "- `lstm_size`: 隠れ状態のサイズ（128）\n",
        "\n",
        "---\n",
        "\n",
        "## **動作イメージ**\n",
        "1. **データの準備**\n",
        "   ```python\n",
        "   dataset = Dataset(\"data.csv\", smiles_col=\"SMILES\")\n",
        "   ```\n",
        "2. **モデルの作成**\n",
        "   ```python\n",
        "   model = LSTM_Generator(dataset)\n",
        "   ```\n",
        "3. **初期状態の作成**\n",
        "   ```python\n",
        "   state = model.init_state(sequence_length=4)\n",
        "   ```\n",
        "4. **ダミー入力データ（文字列インデックス）**\n",
        "   ```python\n",
        "   x = torch.randint(0, len(dataset.uniq_words), (1, 4))  # 例: [[1, 5, 9, 3]]\n",
        "   ```\n",
        "5. **モデルの順伝播**\n",
        "   ```python\n",
        "   logits, new_state = model(x, state)\n",
        "   ```\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "| コンポーネント | 説明 |\n",
        "|--------------|------|\n",
        "| **Embedding 層** | 文字インデックスをベクトルに変換 |\n",
        "| **LSTM 層** | シーケンスデータを処理し、次の文字を予測 |\n",
        "| **全結合層 (FC)** | 各時間ステップでの次の文字の確率分布を出力 |\n",
        "| **init_state()** | LSTM の隠れ状態を初期化 |\n",
        "| **forward()** | 順伝播を実行し、次の文字の予測を行う |\n",
        "\n",
        "このモデルを使うことで、**SMILES の次の文字を予測し、新しい化合物のSMILESを生成する**ことができます。  \n",
        "LSTM を Transformer に変更することで、より高性能なモデルを作成することも可能です。\n",
        "\n",
        "この LSTM モデルをどのように活用したいですか？ 😊"
      ],
      "metadata": {
        "id": "ayYmuH_Pp1Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(dataset, model, text, next_words=50):\n",
        "    words = [text[i] for i in range(len(text))]\n",
        "    model.eval()\n",
        "\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "\n",
        "    return trim_smiles(\"\".join(words))"
      ],
      "metadata": {
        "id": "k0HuQg9pMOUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、**LSTMモデルを用いたSMILES文字列の自動生成（次の文字予測）** を行う関数 `predict()` です。  \n",
        "以下のような動作をします。\n",
        "\n",
        "1. **初期入力文字列 (`text`) から始める**\n",
        "2. **LSTMを使って次の文字を予測**\n",
        "3. **確率分布に基づいてランダムに文字を選択**\n",
        "4. **選ばれた文字を追加し、次の入力として再度予測**\n",
        "5. **指定された長さ (`next_words`) まで繰り返す**\n",
        "6. **最終的なSMILESをトリミングして返す**\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの詳細な解説**\n",
        "### **1. 関数の定義**\n",
        "```python\n",
        "def predict(dataset, model, text, next_words=50):\n",
        "```\n",
        "- `dataset`: **学習済みのデータセット**\n",
        "  - `word_to_index`（文字→インデックスの辞書）や `index_to_word`（インデックス→文字の辞書）を持つ。\n",
        "- `model`: **学習済みの LSTM モデル**\n",
        "- `text`: **予測を開始する初期の SMILES 文字列**\n",
        "- `next_words`: **生成する追加の文字数（デフォルト50）**\n",
        "\n",
        "---\n",
        "\n",
        "### **2. 初期文字の準備**\n",
        "```python\n",
        "words = [text[i] for i in range(len(text))]\n",
        "```\n",
        "- `text` の各文字をリストに分解し、`words` に格納。\n",
        "\n",
        "---\n",
        "\n",
        "### **3. モデルを推論モードに設定**\n",
        "```python\n",
        "model.eval()\n",
        "```\n",
        "- `model.eval()` を呼ぶことで、**推論モード** に変更。\n",
        "- `Dropout` や `BatchNorm` などの動作が訓練時とは異なるため、推論時には `eval()` が必要。\n",
        "\n",
        "---\n",
        "\n",
        "### **4. LSTM の初期状態を作成**\n",
        "```python\n",
        "state_h, state_c = model.init_state(len(words))\n",
        "```\n",
        "- `model.init_state(len(words))` を使って **LSTMの隠れ状態 (`h`, `c`) をゼロベクトルで初期化**。\n",
        "- `state_h, state_c` は LSTM に入力される**隠れ状態（hidden state）とセル状態（cell state）**。\n",
        "\n",
        "---\n",
        "\n",
        "### **5. 文字を順次生成**\n",
        "```python\n",
        "for i in range(0, next_words):\n",
        "```\n",
        "- 指定された `next_words`（50文字）の間、**次の文字を予測** し続ける。\n",
        "\n",
        "#### **(1) 入力データの作成**\n",
        "```python\n",
        "x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
        "```\n",
        "- `words[i:]` の部分列を使って **インデックスのリスト** を作成し、テンソル化。\n",
        "- 例: `\"CCO\"` → `[word_to_index['C'], word_to_index['C'], word_to_index['O']]`\n",
        "\n",
        "#### **(2) LSTM に入力**\n",
        "```python\n",
        "y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "```\n",
        "- LSTM に現在の `x`（入力文字列のインデックス列）と `state_h, state_c`（前の隠れ状態）を渡す。\n",
        "- `y_pred`: LSTM の出力（次の文字のロジット）。\n",
        "- `state_h, state_c`: 更新された隠れ状態。\n",
        "\n",
        "---\n",
        "\n",
        "### **6. 次の文字を選択**\n",
        "```python\n",
        "last_word_logits = y_pred[0][-1]\n",
        "```\n",
        "- `y_pred` の最終時刻の出力（最新の文字に対応するロジット）を取得。\n",
        "- `last_word_logits.shape = (n_vocab,)` （各文字のスコアが含まれる）。\n",
        "\n",
        "#### **(1) 確率分布の計算**\n",
        "```python\n",
        "p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "```\n",
        "- `softmax` を適用し、各文字の確率を計算。\n",
        "- `.detach().numpy()` を使い、**計算グラフから切り離して NumPy 配列に変換**。\n",
        "\n",
        "#### **(2) 確率に基づいてランダムに文字を選択**\n",
        "```python\n",
        "word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "```\n",
        "- `np.random.choice()` を使って、確率 `p` に基づき次の文字のインデックスをランダムに選択。\n",
        "- **確率の高い文字ほど選ばれやすい** が、確率的にランダムな要素もある。\n",
        "\n",
        "#### **(3) 選ばれた文字を `words` に追加**\n",
        "```python\n",
        "words.append(dataset.index_to_word[word_index])\n",
        "```\n",
        "- `index_to_word` を使い、インデックスから文字に変換してリストに追加。\n",
        "\n",
        "---\n",
        "\n",
        "### **7. 生成されたSMILESをトリミング**\n",
        "```python\n",
        "return trim_smiles(\"\".join(words))\n",
        "```\n",
        "- 予測された文字列を結合して SMILES 文字列を作成。\n",
        "- `trim_smiles()` を適用し、**無効な部分を削除** して **化学的に妥当な SMILES に整える**。\n",
        "\n",
        "---\n",
        "\n",
        "## **全体の流れ**\n",
        "1. **最初の文字列 (`text`) を用意**\n",
        "2. **LSTM の初期状態を作成**\n",
        "3. **次の `next_words` 文字を逐次生成**\n",
        "   - **LSTM に入力し、次の文字を予測**\n",
        "   - **確率分布を計算し、ランダムに文字を選択**\n",
        "   - **選択した文字を `words` に追加**\n",
        "4. **最終的な SMILES を整えて出力**\n",
        "\n",
        "---\n",
        "\n",
        "## **例: 動作イメージ**\n",
        "```python\n",
        "dataset = Dataset(\"data.csv\", smiles_col=\"SMILES\")\n",
        "model = LSTM_Generator(dataset)\n",
        "text = \"CCO\"\n",
        "\n",
        "generated_smiles = predict(dataset, model, text, next_words=10)\n",
        "print(generated_smiles)\n",
        "```\n",
        "### **実行結果（例）**\n",
        "```\n",
        "CCOCCN(CC)\n",
        "```\n",
        "- `\"CCO\"` から始まり、10文字が追加され、**有機化合物のSMILESが生成** される。\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "| 処理 | 説明 |\n",
        "|------|------|\n",
        "| **モデルの初期化** | `eval()` に設定 |\n",
        "| **LSTM の初期状態を作成** | `init_state()` を使用 |\n",
        "| **文字列をインデックスに変換** | `word_to_index` を用いる |\n",
        "| **LSTM で次の文字を予測** | `model(x, state)` |\n",
        "| **確率分布から文字を選択** | `softmax` を適用し `np.random.choice()` |\n",
        "| **文字列をトリミング** | `trim_smiles()` で不正な部分を除去 |\n",
        "\n",
        "---\n",
        "\n",
        "## **応用: さらなる改良**\n",
        "1. **より高精度な予測**\n",
        "   - `np.random.choice()` を使わず、`argmax()` にすると**決定論的な予測** になる。\n",
        "   - `temperature`（温度パラメータ）を導入し、**多様性を制御** できる。\n",
        "   \n",
        "2. **Transformer に変更**\n",
        "   - LSTM ではなく、`Transformer` を使うと**より長距離の依存関係を学習** 可能。\n",
        "\n",
        "3. **生成後の構造評価**\n",
        "   - RDKit を用いて、**生成されたSMILESの化学的妥当性をチェック** する。\n",
        "\n",
        "---\n",
        "\n",
        "この関数をどのように活用したいですか？  \n",
        "例えば、**新しい化合物のデザイン** や **特定のパターンを持つSMILESの生成** など、用途に応じてカスタマイズも可能です！ 😊"
      ],
      "metadata": {
        "id": "j6Ah7qpGqIqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def get_best_smiles(dataset, model, next_words=100, max_trial=10, start_length=3):\n",
        "    best_smile = \"\"\n",
        "    for trial in range(max_trial):\n",
        "        starting_text = random.choice(dataset.smiles)[:start_length]\n",
        "        smile = predict(dataset, model, text=starting_text, next_words=next_words)\n",
        "        if len(best_smile) < len(smile):\n",
        "            best_smile = smile\n",
        "    return best_smile"
      ],
      "metadata": {
        "id": "rvMfkv3BMRE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、**LSTM モデルを用いた SMILES 文字列の生成を試行し、最も長いものを選択する** 関数 `get_best_smiles()` です。  \n",
        "\n",
        "---\n",
        "\n",
        "## **コードの詳細な解説**\n",
        "### **1. 関数の定義**\n",
        "```python\n",
        "def get_best_smiles(dataset, model, next_words=100, max_trial=10, start_length=3):\n",
        "```\n",
        "- `dataset`: **SMILES 文字列のデータセット**（`Dataset` クラスのインスタンス）\n",
        "- `model`: **LSTM を用いた文字生成モデル**（`LSTM_Generator` クラスのインスタンス）\n",
        "- `next_words`: **生成する追加の文字数（デフォルト100）**\n",
        "- `max_trial`: **異なるランダムな開始文字列で試行する回数（デフォルト10）**\n",
        "- `start_length`: **開始文字列の長さ（デフォルト3）**\n",
        "  - ランダムに選んだSMILESから `start_length` 文字分を取り出し、生成の起点とする。\n",
        "\n",
        "---\n",
        "\n",
        "### **2. 最良の SMILES を格納する変数を初期化**\n",
        "```python\n",
        "best_smile = \"\"\n",
        "```\n",
        "- `best_smile` には、**現在の最も長いSMILES文字列を格納** する。\n",
        "\n",
        "---\n",
        "\n",
        "### **3. 指定された回数 (`max_trial`) だけ試行**\n",
        "```python\n",
        "for trial in range(max_trial):\n",
        "```\n",
        "- `max_trial` 回（デフォルト 10回）ループを実行し、**異なる開始文字列からSMILESを生成** する。\n",
        "\n",
        "---\n",
        "\n",
        "### **4. ランダムな開始文字列を取得**\n",
        "```python\n",
        "starting_text = random.choice(dataset.smiles)[:start_length]\n",
        "```\n",
        "- `dataset.smiles` から**ランダムに1つSMILESを選択**。\n",
        "- その最初の `start_length` 文字（デフォルト3文字）を取得し、**開始文字列** とする。\n",
        "\n",
        "  **例:**\n",
        "  ```python\n",
        "  dataset.smiles = [\"CCO\", \"CNC=O\", \"CCCBr\"]\n",
        "  start_length = 3\n",
        "  ```\n",
        "  - `random.choice(dataset.smiles)` → `\"CNC=O\"`\n",
        "  - `starting_text = \"CNC\"`\n",
        "\n",
        "---\n",
        "\n",
        "### **5. `predict()` を用いてSMILESを生成**\n",
        "```python\n",
        "smile = predict(dataset, model, text=starting_text, next_words=next_words)\n",
        "```\n",
        "- `predict()` 関数を使い、LSTM に `starting_text` を与えて **次の `next_words` 文字（デフォルト100文字）を生成** する。\n",
        "\n",
        "  **例:**\n",
        "  ```python\n",
        "  starting_text = \"CNC\"\n",
        "  generated_smile = predict(dataset, model, text=\"CNC\", next_words=100)\n",
        "  ```\n",
        "  - 予測されたSMILES → `\"CNC(=O)CCNCCO...\"`\n",
        "\n",
        "---\n",
        "\n",
        "### **6. 現在の `best_smile` と比較して、長ければ更新**\n",
        "```python\n",
        "if len(best_smile) < len(smile):\n",
        "    best_smile = smile\n",
        "```\n",
        "- `smile` の長さが `best_smile` よりも長い場合、`best_smile` を更新。\n",
        "  - これにより、**より長いSMILESを採用** する。\n",
        "\n",
        "---\n",
        "\n",
        "### **7. 最終的な最長のSMILESを返す**\n",
        "```python\n",
        "return best_smile\n",
        "```\n",
        "- `max_trial` 回の試行が終わった後、最も長いSMILESを返す。\n",
        "\n",
        "---\n",
        "\n",
        "## **全体の流れ**\n",
        "1. **ランダムにSMILESを選ぶ**\n",
        "2. **最初の `start_length` 文字を取り出す**\n",
        "3. **その文字列から SMILES を生成**\n",
        "4. **最も長い SMILES を保持**\n",
        "5. **最良のSMILESを返す**\n",
        "\n",
        "---\n",
        "\n",
        "## **実行例**\n",
        "```python\n",
        "dataset = Dataset(\"data.csv\", smiles_col=\"SMILES\")\n",
        "model = LSTM_Generator(dataset)\n",
        "\n",
        "best_smiles = get_best_smiles(dataset, model)\n",
        "print(best_smiles)\n",
        "```\n",
        "\n",
        "### **出力例**\n",
        "```\n",
        "CCOCCN(CC)C(=O)OCCOCC\n",
        "```\n",
        "- 10回試行し、最も長い有効なSMILESが選ばれる。\n",
        "\n",
        "---\n",
        "\n",
        "## **改良のポイント**\n",
        "1. **化学的妥当性の確認**\n",
        "   - 生成された SMILES が **RDKit で妥当な化学構造になるかチェック** する。\n",
        "   ```python\n",
        "   from rdkit import Chem\n",
        "   if Chem.MolFromSmiles(smile) is not None:\n",
        "       valid_smiles.append(smile)\n",
        "   ```\n",
        "   \n",
        "2. **長さだけでなく、特定の性質を考慮**\n",
        "   - **分子量** や **官能基の有無** を考慮して最良のSMILESを選択できる。\n",
        "\n",
        "3. **探索の多様性を向上**\n",
        "   - `random.choice(dataset.smiles)` だけでなく、**温度パラメータを使った予測** などで多様性を増やせる。\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "| 処理 | 説明 |\n",
        "|------|------|\n",
        "| **ランダムにSMILESを選択** | `random.choice(dataset.smiles)[:start_length]` |\n",
        "| **LSTMを使って次の文字を予測** | `predict(dataset, model, text, next_words)` |\n",
        "| **最も長いSMILESを保持** | `if len(best_smile) < len(smile): best_smile = smile` |\n",
        "| **最終的な最長のSMILESを返す** | `return best_smile` |\n",
        "\n",
        "この関数は **より長い（おそらく複雑な）SMILESを生成する** ための戦略として機能します！"
      ],
      "metadata": {
        "id": "D7KNV_I2qYiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def train(dataset, model):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    for epoch in range(MAX_EPOCHS):\n",
        "        state_h, state_c = model.init_state(SEQUENCE_LENGTH)\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "            loss = criterion(y_pred.transpose(1, 2), y)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            state_h = state_h.detach()\n",
        "            state_c = state_c.detach()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"Epoch: {}, Loss: {:.3f}, Generated SMILES: {}\".format(\n",
        "            epoch+1,\n",
        "            total_loss,\n",
        "            get_best_smiles(dataset, model)\n",
        "            )\n",
        "        )\n",
        "        losses.append(total_loss)\n",
        "    return losses"
      ],
      "metadata": {
        "id": "8dTkc7RAMT08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、**LSTM を用いた SMILES 文字列の生成モデルの学習** を行う関数 `train()` です。  \n",
        "\n",
        "---\n",
        "\n",
        "## **コードの詳細な解説**\n",
        "### **1. 関数の定義**\n",
        "```python\n",
        "def train(dataset, model):\n",
        "```\n",
        "- `dataset`: **学習データ**（`Dataset` クラスのインスタンス）\n",
        "- `model`: **LSTM モデル**（`LSTM_Generator` クラスのインスタンス）\n",
        "\n",
        "---\n",
        "\n",
        "### **2. 学習モードに設定**\n",
        "```python\n",
        "losses = []\n",
        "model.train()\n",
        "```\n",
        "- `model.train()` を呼び出して、PyTorch の学習モードに設定。\n",
        "- `losses` リストを作成し、各エポックの損失を記録。\n",
        "\n",
        "---\n",
        "\n",
        "### **3. データローダーの作成**\n",
        "```python\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "```\n",
        "- `torch.utils.data.DataLoader` を使用し、**バッチ単位でデータをロード** する。\n",
        "- `BATCH_SIZE` はグローバル変数として定義されているはず。\n",
        "\n",
        "---\n",
        "\n",
        "### **4. 損失関数と最適化アルゴリズムの定義**\n",
        "```python\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "```\n",
        "- `CrossEntropyLoss()`: **多クラス分類用の損失関数**（単語の確率分布を学習するため）。\n",
        "- `Adam`: **勾配降下法の一種である Adam 最適化アルゴリズム** を使用。\n",
        "- `LEARNING_RATE` はグローバル変数として設定。\n",
        "\n",
        "---\n",
        "\n",
        "### **5. 学習ループの開始**\n",
        "```python\n",
        "for epoch in range(MAX_EPOCHS):\n",
        "```\n",
        "- `MAX_EPOCHS`（グローバル変数）で指定した回数だけ**モデルを学習** する。\n",
        "\n",
        "---\n",
        "\n",
        "### **6. LSTM の隠れ状態 (`state_h`, `state_c`) を初期化**\n",
        "```python\n",
        "state_h, state_c = model.init_state(SEQUENCE_LENGTH)\n",
        "total_loss = 0\n",
        "```\n",
        "- `model.init_state(SEQUENCE_LENGTH)` で **LSTM の隠れ状態を初期化** する。\n",
        "- `total_loss` を 0 にリセット（このエポックの合計損失を記録するため）。\n",
        "\n",
        "---\n",
        "\n",
        "### **7. バッチ単位で学習**\n",
        "```python\n",
        "for batch, (x, y) in enumerate(dataloader):\n",
        "```\n",
        "- `DataLoader` から **バッチ単位でデータ (`x`, `y`) を取得** する。\n",
        "  - `x`: 入力データ（文字列のインデックス列）\n",
        "  - `y`: 正解ラベル（`x` の次の文字）\n",
        "\n",
        "---\n",
        "\n",
        "### **8. 勾配をリセット**\n",
        "```python\n",
        "optimizer.zero_grad()\n",
        "```\n",
        "- **前回の勾配をリセット** し、新しい勾配を計算できるようにする。\n",
        "\n",
        "---\n",
        "\n",
        "### **9. LSTM にデータを入力し、予測値を取得**\n",
        "```python\n",
        "y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "```\n",
        "- LSTM に `x` を入力し、**予測 `y_pred` と次の隠れ状態 `(state_h, state_c)` を取得**。\n",
        "\n",
        "---\n",
        "\n",
        "### **10. 損失の計算**\n",
        "```python\n",
        "loss = criterion(y_pred.transpose(1, 2), y)\n",
        "total_loss += loss.item()\n",
        "```\n",
        "- `y_pred` の次元を `(batch_size, vocab_size, sequence_length)` に変換するために `.transpose(1, 2)` を適用。\n",
        "- `CrossEntropyLoss` を適用し、損失を `total_loss` に加算。\n",
        "\n",
        "---\n",
        "\n",
        "### **11. 隠れ状態の切り離し**\n",
        "```python\n",
        "state_h = state_h.detach()\n",
        "state_c = state_c.detach()\n",
        "```\n",
        "- **`detach()` を適用することで、計算グラフを切り離し**、メモリ使用量を削減。\n",
        "\n",
        "---\n",
        "\n",
        "### **12. 勾配の計算と最適化**\n",
        "```python\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "```\n",
        "- `loss.backward()`: **誤差逆伝播（バックプロパゲーション）** を実行し、各パラメータの勾配を計算。\n",
        "- `optimizer.step()`: **パラメータを更新** して、損失を減らすようにモデルを改善。\n",
        "\n",
        "---\n",
        "\n",
        "### **13. エポックごとのログ出力**\n",
        "```python\n",
        "print(\"Epoch: {}, Loss: {:.3f}, Generated SMILES: {}\".format(\n",
        "    epoch+1,\n",
        "    total_loss,\n",
        "    get_best_smiles(dataset, model)\n",
        "    )\n",
        ")\n",
        "```\n",
        "- **エポックごとに損失 (`total_loss`) と生成された SMILES を出力** する。\n",
        "\n",
        "---\n",
        "\n",
        "### **14. 損失を記録**\n",
        "```python\n",
        "losses.append(total_loss)\n",
        "```\n",
        "- 各エポックの合計損失を `losses` リストに保存。\n",
        "\n",
        "---\n",
        "\n",
        "### **15. 最終的な損失リストを返す**\n",
        "```python\n",
        "return losses\n",
        "```\n",
        "- **全エポック分の損失をリストとして返す**。\n",
        "\n",
        "---\n",
        "\n",
        "## **全体の流れ**\n",
        "1. **データローダーを作成**\n",
        "2. **損失関数と最適化アルゴリズムを定義**\n",
        "3. **エポックごとに学習を実行**\n",
        "   - LSTM の状態を初期化\n",
        "   - バッチごとに予測と損失計算\n",
        "   - 勾配をリセット、誤差逆伝播、パラメータ更新\n",
        "   - 損失を記録\n",
        "   - 生成された SMILES を出力\n",
        "4. **損失のリストを返す**\n",
        "\n",
        "---\n",
        "\n",
        "## **実行例**\n",
        "```python\n",
        "dataset = Dataset(\"data.csv\", smiles_col=\"SMILES\")\n",
        "model = LSTM_Generator(dataset)\n",
        "\n",
        "losses = train(dataset, model)\n",
        "```\n",
        "\n",
        "### **出力例**\n",
        "```\n",
        "Epoch: 1, Loss: 23.450, Generated SMILES: CCOCCN\n",
        "Epoch: 2, Loss: 21.873, Generated SMILES: CNC(=O)O\n",
        "Epoch: 3, Loss: 19.420, Generated SMILES: CCCBr\n",
        "...\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **改良のポイント**\n",
        "1. **学習率スケジューリング**\n",
        "   - `torch.optim.lr_scheduler` を使って、エポックが進むにつれて学習率を減少させる。\n",
        "   ```python\n",
        "   scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "   scheduler.step()\n",
        "   ```\n",
        "\n",
        "2. **勾配クリッピング**\n",
        "   - `torch.nn.utils.clip_grad_norm_()` を使い、大きな勾配を抑えて学習を安定化。\n",
        "   ```python\n",
        "   torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
        "   ```\n",
        "\n",
        "3. **より高度なデータ前処理**\n",
        "   - SMILES のトークン化を改善し、より意味のある単位で処理する。\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "| 処理 | 説明 |\n",
        "|------|------|\n",
        "| **データローダー作成** | `DataLoader(dataset, batch_size=BATCH_SIZE)` |\n",
        "| **損失関数と最適化手法の定義** | `CrossEntropyLoss()` + `Adam(model.parameters())` |\n",
        "| **エポックごとに学習** | `for epoch in range(MAX_EPOCHS):` |\n",
        "| **バッチ単位で処理** | `for batch, (x, y) in enumerate(dataloader):` |\n",
        "| **LSTM に入力を与えて予測** | `y_pred, (state_h, state_c) = model(x, (state_h, state_c))` |\n",
        "| **損失計算** | `loss = criterion(y_pred.transpose(1, 2), y)` |\n",
        "| **バックプロパゲーション** | `loss.backward()` |\n",
        "| **パラメータ更新** | `optimizer.step()` |\n",
        "| **学習の進行状況を表示** | `print(\"Epoch: {}, Loss: {:.3f}, Generated SMILES: {}\".format(...))` |\n",
        "\n",
        "この `train()` 関数は、LSTM を使った **SMILES 文字列の生成モデルを学習させるための基本的なトレーニングループ** になっています！ 🚀"
      ],
      "metadata": {
        "id": "EL5CkitGqsB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "def train(dataset, model):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    for epoch in range(MAX_EPOCHS):\n",
        "        state_h, state_c = model.init_state(SEQUENCE_LENGTH)\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "            loss = criterion(y_pred.transpose(1, 2), y)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            state_h = state_h.detach()\n",
        "            state_c = state_c.detach()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"Epoch: {}, Loss: {:.3f}, Generated SMILES: {}\".format(\n",
        "            epoch+1,\n",
        "            total_loss,\n",
        "            get_best_smiles(dataset, model)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Add the total loss to the list of losses\n",
        "        losses.append(total_loss)\n",
        "\n",
        "        # Save the model and loss history\n",
        "        torch.save(model.state_dict(), '/content/drive/My Drive/day6/model_epoch{}.pth'.format(epoch+1))\n",
        "        with open('/content/drive/My Drive/day6/losses_epoch{}.pkl'.format(epoch+1), 'wb') as f:\n",
        "            pickle.dump(losses, f)\n",
        "\n",
        "    return losses"
      ],
      "metadata": {
        "id": "tRgsYezEMW8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、**LSTM を用いた SMILES 文字列生成モデルの学習** を行う関数 `train()` で、前回の `train()` に **モデルの保存機能** が追加されています。  \n",
        "\n",
        "---\n",
        "\n",
        "## **追加された機能**\n",
        "- **学習過程でのモデル保存** (`torch.save`)\n",
        "- **損失履歴の保存** (`pickle.dump`)\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの詳細な解説**\n",
        "### **1. 必要なライブラリのインポート**\n",
        "```python\n",
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "```\n",
        "- `os`: ファイルパスの操作のために使用。\n",
        "- `pickle`: **Python オブジェクトを保存・読み込み** するために使用。\n",
        "- `torch`: PyTorch の機械学習フレームワーク。\n",
        "\n",
        "---\n",
        "\n",
        "### **2. 関数の定義**\n",
        "```python\n",
        "def train(dataset, model):\n",
        "```\n",
        "- `dataset`: **学習データ**（`Dataset` クラスのインスタンス）\n",
        "- `model`: **LSTM モデル**（`LSTM_Generator` クラスのインスタンス）\n",
        "\n",
        "---\n",
        "\n",
        "### **3. 学習モードの設定**\n",
        "```python\n",
        "losses = []\n",
        "model.train()\n",
        "```\n",
        "- `model.train()` を呼び出して、**PyTorch の学習モードに設定** する。\n",
        "- `losses` リストを作成し、**各エポックの損失を記録** する。\n",
        "\n",
        "---\n",
        "\n",
        "### **4. データローダーの作成**\n",
        "```python\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "```\n",
        "- `torch.utils.data.DataLoader` を使い、**データをバッチ単位でロード** する。\n",
        "- `BATCH_SIZE` はグローバル変数。\n",
        "\n",
        "---\n",
        "\n",
        "### **5. 損失関数と最適化アルゴリズムの設定**\n",
        "```python\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "```\n",
        "- **損失関数**: `CrossEntropyLoss()`（多クラス分類向け）。\n",
        "- **最適化手法**: `Adam`（勾配降下法の一種）。\n",
        "- `LEARNING_RATE` は学習率（グローバル変数）。\n",
        "\n",
        "---\n",
        "\n",
        "### **6. 学習ループの開始**\n",
        "```python\n",
        "for epoch in range(MAX_EPOCHS):\n",
        "```\n",
        "- `MAX_EPOCHS`（グローバル変数）だけ学習を繰り返す。\n",
        "\n",
        "---\n",
        "\n",
        "### **7. LSTM の隠れ状態 (`state_h`, `state_c`) を初期化**\n",
        "```python\n",
        "state_h, state_c = model.init_state(SEQUENCE_LENGTH)\n",
        "total_loss = 0\n",
        "```\n",
        "- `SEQUENCE_LENGTH`（グローバル変数）を用いて、**LSTM の隠れ状態を初期化** する。\n",
        "- `total_loss` を 0 にリセット（エポックごとの損失を記録）。\n",
        "\n",
        "---\n",
        "\n",
        "### **8. バッチ単位で学習**\n",
        "```python\n",
        "for batch, (x, y) in enumerate(dataloader):\n",
        "    optimizer.zero_grad()\n",
        "```\n",
        "- `x`（入力）と `y`（正解ラベル）を `dataloader` から取得。\n",
        "- **前回の勾配をリセット** し、新しい勾配を計算できるようにする。\n",
        "\n",
        "---\n",
        "\n",
        "### **9. LSTM で予測値を計算**\n",
        "```python\n",
        "y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "```\n",
        "- LSTM に `x` を入力し、**予測 `y_pred` と次の隠れ状態 `(state_h, state_c)` を取得**。\n",
        "\n",
        "---\n",
        "\n",
        "### **10. 損失を計算**\n",
        "```python\n",
        "loss = criterion(y_pred.transpose(1, 2), y)\n",
        "total_loss += loss.item()\n",
        "```\n",
        "- `y_pred.transpose(1, 2)`: `CrossEntropyLoss` に適した形 `(batch_size, vocab_size, sequence_length)` に変換。\n",
        "- 損失 `loss` を計算し、`total_loss` に加算。\n",
        "\n",
        "---\n",
        "\n",
        "### **11. 隠れ状態の切り離し**\n",
        "```python\n",
        "state_h = state_h.detach()\n",
        "state_c = state_c.detach()\n",
        "```\n",
        "- **`detach()` を適用して計算グラフを切り離し**、メモリ使用量を削減。\n",
        "\n",
        "---\n",
        "\n",
        "### **12. 勾配の計算と最適化**\n",
        "```python\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "```\n",
        "- `loss.backward()`: **誤差逆伝播（バックプロパゲーション）** を実行。\n",
        "- `optimizer.step()`: **パラメータを更新** して、損失を減らす。\n",
        "\n",
        "---\n",
        "\n",
        "### **13. エポックごとのログ出力**\n",
        "```python\n",
        "print(\"Epoch: {}, Loss: {:.3f}, Generated SMILES: {}\".format(\n",
        "    epoch+1,\n",
        "    total_loss,\n",
        "    get_best_smiles(dataset, model)\n",
        "    )\n",
        ")\n",
        "```\n",
        "- エポックごとに損失 (`total_loss`) と**生成された SMILES を出力**。\n",
        "\n",
        "---\n",
        "\n",
        "### **14. 損失を記録**\n",
        "```python\n",
        "losses.append(total_loss)\n",
        "```\n",
        "- 各エポックの合計損失を `losses` リストに保存。\n",
        "\n",
        "---\n",
        "\n",
        "### **15. モデルと損失履歴の保存**\n",
        "```python\n",
        "torch.save(model.state_dict(), '/content/drive/My Drive/day6/model_epoch{}.pth'.format(epoch+1))\n",
        "```\n",
        "- **学習済みのモデルのパラメータ** を Google Drive に保存。\n",
        "- `torch.save(model.state_dict(), filename)`: `state_dict()` を保存し、後で `model.load_state_dict()` で復元可能。\n",
        "\n",
        "```python\n",
        "with open('/content/drive/My Drive/day6/losses_epoch{}.pkl'.format(epoch+1), 'wb') as f:\n",
        "    pickle.dump(losses, f)\n",
        "```\n",
        "- `pickle.dump(losses, f)`: **損失履歴を保存** し、学習の推移を後で確認可能。\n",
        "\n",
        "---\n",
        "\n",
        "### **16. 最終的な損失リストを返す**\n",
        "```python\n",
        "return losses\n",
        "```\n",
        "- 全エポック分の損失をリストとして返す。\n",
        "\n",
        "---\n",
        "\n",
        "## **全体の流れ**\n",
        "1. **データローダーを作成**\n",
        "2. **損失関数と最適化手法の定義**\n",
        "3. **エポックごとに学習**\n",
        "   - LSTM の隠れ状態を初期化\n",
        "   - バッチごとに予測と損失計算\n",
        "   - 勾配をリセット、誤差逆伝播、パラメータ更新\n",
        "   - 損失を記録\n",
        "   - 生成された SMILES を出力\n",
        "   - **モデルと損失履歴を保存**\n",
        "4. **損失のリストを返す**\n",
        "\n",
        "---\n",
        "\n",
        "## **実行例**\n",
        "```python\n",
        "dataset = Dataset(\"data.csv\", smiles_col=\"SMILES\")\n",
        "model = LSTM_Generator(dataset)\n",
        "\n",
        "losses = train(dataset, model)\n",
        "```\n",
        "\n",
        "### **出力例**\n",
        "```\n",
        "Epoch: 1, Loss: 23.450, Generated SMILES: CCOCCN\n",
        "Epoch: 2, Loss: 21.873, Generated SMILES: CNC(=O)O\n",
        "Epoch: 3, Loss: 19.420, Generated SMILES: CCCBr\n",
        "...\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **改良のポイント**\n",
        "1. **Google Drive のディレクトリチェック**\n",
        "   ```python\n",
        "   os.makedirs('/content/drive/My Drive/day6', exist_ok=True)\n",
        "   ```\n",
        "   - 保存先のディレクトリが存在しない場合に作成。\n",
        "\n",
        "2. **モデルの定期的な保存**\n",
        "   - 5 エポックごとに保存するように変更：\n",
        "   ```python\n",
        "   if (epoch+1) % 5 == 0:\n",
        "       torch.save(model.state_dict(), 'model_epoch{}.pth'.format(epoch+1))\n",
        "   ```\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "この `train()` 関数は、**LSTM による SMILES 生成モデルの学習を行いながら、モデルと損失履歴を Google Drive に保存するように設計** されています！ 🚀"
      ],
      "metadata": {
        "id": "nonIJ-N4rAiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Driveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruSaC_ygMtlS",
        "outputId": "e22bc9a9-5588-40c4-e425-5bcca3dfdb9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、Google Colab で **Google Drive をマウント** するためのものです。\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの解説**\n",
        "```python\n",
        "# Google Driveをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "```\n",
        "\n",
        "### **1. `from google.colab import drive`**\n",
        "- `google.colab` モジュールから `drive` をインポート。\n",
        "- Google Colab で **Google Drive の操作を可能にするライブラリ**。\n",
        "\n",
        "### **2. `drive.mount('/content/drive')`**\n",
        "- **Google Drive を `/content/drive` にマウント** する。\n",
        "- 実行すると、**Google アカウントの認証を求めるプロンプトが表示** される。\n",
        "- 認証後、Google Drive 内のファイルにアクセス可能。\n",
        "\n",
        "---\n",
        "\n",
        "## **マウント後のファイルアクセス**\n",
        "Google Drive をマウントすると、Colab から Drive のファイルを通常のフォルダと同じように操作できます。\n",
        "\n",
        "例えば：\n",
        "```python\n",
        "import os\n",
        "\n",
        "# Google Drive 内のファイルを確認\n",
        "os.listdir(\"/content/drive/My Drive/\")\n",
        "```\n",
        "- `/content/drive/My Drive/` は Google Drive のルートディレクトリ。\n",
        "- `os.listdir()` で Drive 内のファイル一覧を取得。\n",
        "\n",
        "---\n",
        "\n",
        "## **ファイルの保存**\n",
        "学習済みモデルなどを Google Drive に保存する例：\n",
        "```python\n",
        "torch.save(model.state_dict(), \"/content/drive/My Drive/model.pth\")\n",
        "```\n",
        "- これにより、Google Drive に `model.pth` として保存可能。\n",
        "\n",
        "---\n",
        "\n",
        "## **Google Drive からファイルを読み込む**\n",
        "例えば、CSV データを読み込む場合：\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/data.csv\")\n",
        "print(df.head())\n",
        "```\n",
        "- Google Drive 内の `data.csv` を Pandas で読み込む。\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "- `drive.mount('/content/drive')` を実行すると、Google Drive を Colab に接続できる。\n",
        "- Drive 内のファイルを `\"/content/drive/My Drive/\"` 経由で操作可能。\n",
        "- **学習データの保存や読み込みに便利！** 🚀"
      ],
      "metadata": {
        "id": "qFco6WwurLCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://raw.githubusercontent.com/maskot1977/tmd2020/main/data/data_0.csv\"\n",
        "SMILES_COL = \"Open Babel SMILES\"\n",
        "\n",
        "MAX_EPOCHS = 200\n",
        "BATCH_SIZE = 128\n",
        "SEQUENCE_LENGTH = 4\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "dataset = Dataset(url=URL, smiles_col=SMILES_COL)\n",
        "model = LSTM_Generator(dataset)\n",
        "losses = train(dataset, model)"
      ],
      "metadata": {
        "id": "BKaaw431MbTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、**SMILES 文字列の生成を目的とした LSTM モデルの学習を開始するスクリプト** です。以下の流れで動作します。\n",
        "\n",
        "---\n",
        "\n",
        "## **1. 事前設定**\n",
        "```python\n",
        "URL = \"https://raw.githubusercontent.com/maskot1977/tmd2020/main/data/data_0.csv\"\n",
        "SMILES_COL = \"Open Babel SMILES\"\n",
        "```\n",
        "- **SMILES 形式**（化学構造を表現する文字列）のデータセットを指定。\n",
        "- `URL` にはデータの CSV ファイルのパスが含まれる。\n",
        "- `SMILES_COL` は、CSV 内で SMILES 文字列が格納されているカラム名。\n",
        "\n",
        "---\n",
        "\n",
        "## **2. ハイパーパラメータの設定**\n",
        "```python\n",
        "MAX_EPOCHS = 200        # 学習のエポック数（200回）\n",
        "BATCH_SIZE = 128        # バッチサイズ（1回の学習で使用するデータ数）\n",
        "SEQUENCE_LENGTH = 4     # 入力のシーケンス長（LSTMに与える文字数）\n",
        "LEARNING_RATE = 0.001   # 学習率（最適化アルゴリズムの更新の大きさ）\n",
        "```\n",
        "- **エポック数 (`MAX_EPOCHS`)**  \n",
        "  - 何回データ全体を学習するかを指定（ここでは200回）。\n",
        "- **バッチサイズ (`BATCH_SIZE`)**  \n",
        "  - 一度の更新で使うデータ数（128個）。\n",
        "- **シーケンス長 (`SEQUENCE_LENGTH`)**  \n",
        "  - LSTM に入力する文字の長さ（4文字ずつ学習）。\n",
        "- **学習率 (`LEARNING_RATE`)**  \n",
        "  - 学習のスピードを決定（0.001）。\n",
        "\n",
        "---\n",
        "\n",
        "## **3. データセットの準備**\n",
        "```python\n",
        "dataset = Dataset(url=URL, smiles_col=SMILES_COL)\n",
        "```\n",
        "- `Dataset` クラスのインスタンスを作成。\n",
        "- `URL` から CSV を読み込み、**SMILES 文字列を LSTM に適したデータ形式** に変換。\n",
        "\n",
        "---\n",
        "\n",
        "## **4. LSTM モデルの作成**\n",
        "```python\n",
        "model = LSTM_Generator(dataset)\n",
        "```\n",
        "- `LSTM_Generator` クラスのインスタンスを作成。\n",
        "- `dataset` を用いて、LSTM の入力層（埋め込み層）の語彙サイズを決定。\n",
        "\n",
        "---\n",
        "\n",
        "## **5. モデルの学習開始**\n",
        "```python\n",
        "losses = train(dataset, model)\n",
        "```\n",
        "- `train()` 関数を実行し、**LSTM を SMILES 文字列の生成タスクに適用**。\n",
        "- 学習の進行状況（エポックごとの損失）をリスト `losses` に記録。\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの全体の流れ**\n",
        "1. **データセットをダウンロード**（`Dataset` クラス）\n",
        "2. **LSTM モデルを定義**（`LSTM_Generator` クラス）\n",
        "3. **学習を開始**（`train()` 関数）\n",
        "\n",
        "このコードを実行すると、**化学構造の SMILES 文字列を学習し、新しい SMILES を生成する LSTM モデルが訓練される** 🚀"
      ],
      "metadata": {
        "id": "RzRFOJ5lrXir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# モデルとロスの履歴の読み込み\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/day6/model_epoch200.pth')) # パスは書き換えてください\n",
        "with open('/content/drive/My Drive/day6/losses_epoch200.pkl', 'rb') as f:\n",
        "    losses = pickle.load(f)\n",
        "\n",
        "# ロスの履歴の図示\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss History')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "4sVMr9ttMd1f",
        "outputId": "a109d5cb-ae63-4f22-bd5d-0ce6568973e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、**学習済みの LSTM モデルを読み込み、トレーニング時の損失（Loss）の履歴を可視化** するものです。\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの解説**\n",
        "### **1. 必要なライブラリのインポート**\n",
        "```python\n",
        "import torch\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "```\n",
        "- `torch`：学習済みの PyTorch モデルをロードするために使用。\n",
        "- `pickle`：保存された損失（Loss）の履歴を読み込むために使用。\n",
        "- `matplotlib.pyplot`：損失の履歴を可視化するために使用。\n",
        "\n",
        "---\n",
        "\n",
        "### **2. モデルとロスの履歴を読み込む**\n",
        "```python\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/day6/model_epoch200.pth'))\n",
        "```\n",
        "- `torch.load()` を使い、Google Drive に保存された **エポック200時点の学習済みモデルのパラメータをロード**。\n",
        "- `model.load_state_dict()` により、既存の `model` にロードしたパラメータを適用。\n",
        "- `/content/drive/My Drive/day6/model_epoch200.pth` は、学習時に `train()` 関数で保存したモデル。\n",
        "\n",
        "```python\n",
        "with open('/content/drive/My Drive/day6/losses_epoch200.pkl', 'rb') as f:\n",
        "    losses = pickle.load(f)\n",
        "```\n",
        "- `pickle.load()` で **学習中のロス（Loss）の履歴を復元**。\n",
        "- `losses_epoch200.pkl` は `train()` 関数内で保存した損失データ。\n",
        "\n",
        "---\n",
        "\n",
        "### **3. 損失の履歴をグラフ化**\n",
        "```python\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss History')\n",
        "plt.show()\n",
        "```\n",
        "- `plt.plot(losses)`：損失の履歴をプロット。\n",
        "- `plt.xlabel('Epochs')`：横軸に **エポック数** を設定。\n",
        "- `plt.ylabel('Loss')`：縦軸に **損失** を設定。\n",
        "- `plt.title('Training Loss History')`：グラフのタイトルを設定。\n",
        "- `plt.show()`：グラフを表示。\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの実行結果**\n",
        "- **横軸：エポック数（学習の進行）**\n",
        "- **縦軸：損失（Loss の値）**\n",
        "- **グラフの形状**\n",
        "  - 順調に学習が進めば、損失は **徐々に減少** するはず。\n",
        "  - もし途中で**損失が減らなくなったり増加する場合**、学習率 (`LEARNING_RATE`) やエポック数 (`MAX_EPOCHS`) の調整が必要。\n",
        "\n",
        "---\n",
        "\n",
        "## **まとめ**\n",
        "- **学習済み LSTM モデルを Google Drive からロード**\n",
        "- **学習中の損失（Loss）の履歴を可視化**\n",
        "- **モデルの収束状況を確認し、学習が適切に進んだかを分析**\n",
        "\n",
        "このコードを使えば、**モデルのトレーニング状況を確認し、過学習や収束の問題を特定** できます！📉🚀"
      ],
      "metadata": {
        "id": "IpmV85i3rj9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generated_smiles = predict(dataset, model, text='C')\n",
        "print(generated_smiles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrW5t_wpNP4S",
        "outputId": "8c224c41-e6d0-4b9a-c8e1-71a4062f3842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C(=N)Nc1cccc(c1)CCN(CCc1ccc(o1)C)CCc1cccc(n1)COC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[14:10:25] SMILES Parse Error: extra open parentheses while parsing: C(=N)Nc1cccc(c1)CCN(CCc1ccc(o1)C)CCc1cccc(n1)COC(=O\n",
            "[14:10:25] SMILES Parse Error: check for mistakes around position 49:\n",
            "[14:10:25] o1)C)CCc1cccc(n1)COC(=O\n",
            "[14:10:25] ~~~~~~~~~~~~~~~~~~~~^\n",
            "[14:10:25] SMILES Parse Error: Failed parsing SMILES 'C(=N)Nc1cccc(c1)CCN(CCc1ccc(o1)C)CCc1cccc(n1)COC(=O' for input: 'C(=N)Nc1cccc(c1)CCN(CCc1ccc(o1)C)CCc1cccc(n1)COC(=O'\n",
            "[14:10:25] SMILES Parse Error: syntax error while parsing: C(=N)Nc1cccc(c1)CCN(CCc1ccc(o1)C)CCc1cccc(n1)COC(=\n",
            "[14:10:25] SMILES Parse Error: check for mistakes around position 50:\n",
            "[14:10:25] 1)C)CCc1cccc(n1)COC(=\n",
            "[14:10:25] ~~~~~~~~~~~~~~~~~~~~^\n",
            "[14:10:25] SMILES Parse Error: Failed parsing SMILES 'C(=N)Nc1cccc(c1)CCN(CCc1ccc(o1)C)CCc1cccc(n1)COC(=' for input: 'C(=N)Nc1cccc(c1)CCN(CCc1ccc(o1)C)CCc1cccc(n1)COC(='\n",
            "[14:10:25] SMILES Parse Error: syntax error while parsing: C(=N)Nc1cccc(c1)CCN(CCc1ccc(o1)C)CCc1cccc(n1)COC(\n",
            "[14:10:25] SMILES Parse Error: check for mistakes around position 49:\n",
            "[14:10:25] o1)C)CCc1cccc(n1)COC(\n",
            "[14:10:25] ~~~~~~~~~~~~~~~~~~~~^\n",
            "[14:10:25] SMILES Parse Error: Failed parsing SMILES 'C(=N)Nc1cccc(c1)CCN(CCc1ccc(o1)C)CCc1cccc(n1)COC(' for input: 'C(=N)Nc1cccc(c1)CCN(CCc1ccc(o1)C)CCc1cccc(n1)COC('\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、**LSTM モデルを使って SMILES 文字列を生成し、その結果を表示する** ものです。\n",
        "\n",
        "---\n",
        "\n",
        "## **コードの解説**\n",
        "```python\n",
        "generated_smiles = predict(dataset, model, text='C')\n",
        "```\n",
        "- `predict()` 関数を使用して、LSTM モデル `model` に **\"C\"** という文字列を入力し、SMILES 文字列を生成。\n",
        "- `dataset` には、SMILES 文字列のデータが格納されている。\n",
        "- `model` は、学習済みの LSTM 文字列生成モデル。\n",
        "\n",
        "```python\n",
        "print(generated_smiles)\n",
        "```\n",
        "- 生成された **SMILES 文字列を表示**。\n",
        "\n",
        "---\n",
        "\n",
        "## **背景となる処理**\n",
        "### **`predict()` 関数の動作**\n",
        "```python\n",
        "def predict(dataset, model, text, next_words=50):\n",
        "    words = [text[i] for i in range(len(text))]\n",
        "    model.eval()\n",
        "\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "\n",
        "    return trim_smiles(\"\".join(words))\n",
        "```\n",
        "1. **初期入力**：与えられた `text`（例: `\"C\"`）を LSTM に入力。\n",
        "2. **LSTM の初期状態を作成** (`state_h, state_c`)。\n",
        "3. **次の 50 文字を予測** (`next_words=50`)：\n",
        "   - モデルが次の文字を予測し、確率分布に基づいて **ランダムに選択**。\n",
        "   - 予測された文字を `words` に追加。\n",
        "4. **`trim_smiles()` で適切な SMILES 文字列に整形**。\n",
        "5. **最終的な SMILES 文字列を返す**。\n",
        "\n",
        "---\n",
        "\n",
        "## **実行例**\n",
        "```python\n",
        "generated_smiles = predict(dataset, model, text='C')\n",
        "print(generated_smiles)\n",
        "```\n",
        "**出力例**（LSTM による生成）\n",
        "```\n",
        "CC(=O)OC1=CC=CC=C1C(=O)O\n",
        "```\n",
        "このように、**LSTM を用いて新しい化学構造の SMILES 文字列を生成する** ことができます。\n",
        "\n",
        "---\n",
        "\n",
        "## **ポイント**\n",
        "- `text='C'` をスタートとして **新しい SMILES 文字列を予測**。\n",
        "- 50文字程度の長さまで **LSTM が次の文字を順に予測**。\n",
        "- `print(generated_smiles)` で結果を確認。\n",
        "\n",
        "このコードを活用すると、**データから学習した LSTM を用いて新規の分子構造を自動生成** できます！ 🧪🔬🚀"
      ],
      "metadata": {
        "id": "laxQqdWSrw0n"
      }
    }
  ]
}